[
  {
    "objectID": "04-text-IR.html",
    "href": "04-text-IR.html",
    "title": "Búsqueda de Texto Completo",
    "section": "",
    "text": "Índice invertido\n  \n  Búsqueda mediante un índice invertido\n  \n  Preparación del ambiente\n  Creación del modelo de preprocesamiento y tokenización de texto\n  \n  Distribución del vocabulario (Ley de Zipf)\n  \n  Sobre el pesado de términos\n  \n  Frecuencia de término (TF)\n  Frecuencia de documento inversa (\\(\\textsf{IDF}\\))\n  Combinando pesado local y global - \\(\\textsf{TFIDF}\\)\n  Creación de una bolsa de palabras (pesado binario)\n  Creación de un modelo TFIDF\n  \n  Búsqueda por fuerza bruta\n  Búsqueda con índice\n  Consultas libres\n  \n  Ejercicios\nLos ejercicios de esta unidad se encuentra disponible en Colab en el siguiente notebook https://colab.research.google.com/drive/1gnvWLHtxFK9qtBHw5p8wTQfyhZop4oSx?usp=sharing"
  },
  {
    "objectID": "04-text-IR.html#índice-invertido",
    "href": "04-text-IR.html#índice-invertido",
    "title": "Búsqueda de Texto Completo",
    "section": "Índice invertido",
    "text": "Índice invertido\nUn índice invertido es una representación dispersa de la matriz \\(W_{m,n}\\) formada por \\(m\\) componentes y \\(n\\) documentos, i.e., cada celda \\(w_{t,i}\\) es el peso asignado para el término \\(t\\) que ocurre en el documento \\(i\\). Por construcción, esta matriz tiene una gran cantidad de ceros, por lo que \\(W\\) es altamente dispersa (pocos términos ocurren en un documento).\n\\[ W \\left\\{\n\\begin{array}{rrrr r}\n                & \\vec x_1& \\vec x_2&       & \\vec x_n \\\\\nt_1 \\rightarrow & w_{1,1} & w_{1,2} & \\dots & w_{1,n} \\\\\nt_2 \\rightarrow & w_{2,1} & w_{2,2} &       & w_{2,n} \\\\\n                & \\vdots  &         & \\ddots&         \\\\\nt_m \\rightarrow & w_{m,1} & w_{m,2} &       & w_{m,n} \\\\\n\\end{array}\n\\right.\n\\]\nLa representación es entonces por fila, a manera de lista de adjacencia; esto es, cada fila \\(t\\) es representada por las tuplas \\((i, w_{t,i})\\), esto es, un índice invertido es la siguiente estructura \\(W^*\\)\n\\[ W^* \\left\\{\n\\begin{array}{rrr}\nt_1 & \\rightarrow & \\{(i, w_{1, i})\\} \\\\\nt_2 & \\rightarrow & \\{(i, w_{2, i})\\} \\\\\n\\vdots & \\vdots   &  \\hfill \\vdots \\hfill \\\\\nt_m & \\rightarrow & \\{(i, w_{m, i})\\} \\\\\n\\end{array}\n\\right.\n\\]\nla tupla es usada siempre y cuando \\(w &gt; 0\\). Las tuplas suelen ordenarse por su identificador de columna, pero también puede usarse el peso según convenga. A las filas suele llamarseles listas de posteo (posting lists). Los requerimientos de una matriz densa son altísimos ya que las representaciones de texto suelen ser de muy alta dimensión. Si la representación contiene muchos ceros, como es el caso de una representación basada en un modelo léxico, es posible representar las matrices de manera dispersa y reducir enormemente los requisitos de la memoría. Como se verá a continuación la representación también influye enormemente en los tiempos de procesamiento.\n\nBúsqueda mediante un índice invertido\nLa solución na\"ive de una obtener los \\(k\\) documentos más similares es evaluar todos los vectores \\(\\vec{x}_i\\), i.e., columnas de \\(W\\), y determinar aquellos más similares, i.e., minimizar \\(d(\\vec{x}_i, q)\\).\nEl índice invertido \\(W^*\\) contiene la información necesaria para realizar esta operación de manera eficiente. Primeramente, es necesario analizar la expresión de \\(\\cos\\). El denominador \\(\\sqrt{\\sum_i u_i^2} \\cdot \\sqrt{\\sum_i q_i^2}\\), en sus partes es estático para cada vector, por lo que se puede preprocesar y no calcular de manera explícita para cada evaluación de \\(\\cos\\). Con respecto al numerador corresponde al producto punto entre \\(\\vec{u}\\) y \\(\\vec{q}\\), \\(\\sum_i u_i \\cdot q_i\\). Dicho esto, solo es necesario calcular los productos diferentes de cero; así pues, la evaluación eficiente de \\(\\cos\\) corresponde con una evaluación eficiente de la intersección de las componentes diferentes de cero. Los algoritmos como SvS, BY o BK, pueden ser de gran ayuda para este cálculo. Note que aunque que los pesos con valor cero no se representan en \\(W^*\\), dicho índice representa información por fila, lo cual no permite hacer operaciones eficientes entre \\(q\\) y los vectores columna \\(\\vec x\\) individuales.\nAfortunadamente, la evaluación se puede hacer eficiente para todo el conjunto de posibles candidatos (aquellos donde el producto punto contra \\(q\\) sea diferente de cero). Para esto, se toman las componentes diferentes de cero en \\(q\\), se toman las listas de adyacencia de \\(W^*\\) y se procede a unirlas de manera eficiente. El conjunto de identificadores de documento resultado de esta unión será aquel que debe ser evaluado para obtener el conjunto de documentos similares. Si uno toma la intersección, que puede ser más veloz de calcular, entonces podrían perderse documentos relevantes; es posible también mandar el problema a un punto intermedio, es decir al problema de \\(t\\)-thresholds, donde se recupera un conjunto donde cada uno de los miembros aparece en al menos \\(t\\) listas. La manera más eficiente, sin embargo, es realizar optimizaciones por filtrado de pesos o mejorando los esquemas de pesado; la idea general entonces es desaparecer entradas de \\(W*\\) de tal forma que la unión sea siempre pequeña. La adecuada optimización de un índice invertido puede hacerlo escalable a niveles realmente impresionantes.\nLos algoritmos de BK pueden ser utilizados para calcular la unión y t-thresholds, así como los algoritmos de mezcla clásicos (merge). Es posible unir la operación de unión con la operación de producto punto por vector usando los algoritmos adecuados.\n\nhttps://github.com/sadit/InvertedFiles.jl/blob/main/src/invfilesearch.jl\nhttps://github.com/sadit/InvertedFiles.jl/blob/main/src/winvfilesearch.jl\nhttps://github.com/sadit/Intersections.jl/blob/main/src/imerge.jl\nhttps://github.com/sadit/Intersections.jl/blob/main/src/umerge.jl\nhttps://github.com/sadit/Intersections.jl/blob/main/src/xmerge.jl"
  },
  {
    "objectID": "04-text-IR.html#preparación-del-ambiente",
    "href": "04-text-IR.html#preparación-del-ambiente",
    "title": "Búsqueda de Texto Completo",
    "section": "Preparación del ambiente",
    "text": "Preparación del ambiente\n\nusing CSV, DataFrames, Downloads\nusing SimilaritySearch, TextSearch, InvertedFiles\nusing StatsBase, JSON3, Cobweb\nusing LinearAlgebra\nusing PlotlyLight\nPlotlyLight.settings.use_iframe = true  # necesario para quarto / jupyter / etc.\n\ntrue\n\n\nAhora, podemos descargar nuestros datos. Estos serán la parte en Español de la base de datos WIT (Wikipedia Image Text).\n\nmetafile = \"es-wit-text.tsv\"\nif !isfile(metafile)\n    Downloads.download(\"https://huggingface.co/datasets/sadit/WIT-es_jina-clip-v2_sample/resolve/main/es-wit-text.tsv?download=true\", metafile)\nend\n\nA continuación se carga el archivo de datos:\n\n\nD = CSV.read(metafile, DataFrame)\nnames(D)\n\n19-element Vector{String}:\n \"language\"\n \"page_url\"\n \"image_url\"\n \"page_title\"\n \"section_title\"\n \"hierarchical_section_title\"\n \"caption_reference_description\"\n \"caption_attribution_description\"\n \"caption_alt_text_description\"\n \"mime_type\"\n \"original_height\"\n \"original_width\"\n \"is_main_image\"\n \"attribution_passes_lang_id\"\n \"page_changed_recently\"\n \"context_page_description\"\n \"context_section_description\"\n \"ID\"\n \"image_url_sha256\"\n\n\nUn ejemplo de lo que viene en cada registro:\n\nDict(pairs(D[1, :]))\n\nDict{Symbol, Any} with 19 entries:\n  :image_url_sha256                =&gt; \"14f55329b6d8f9e7125ae6288af2e82807285f11…\n  :ID                              =&gt; String15(\"00000_0000009\")\n  :caption_reference_description   =&gt; \"Torreón en el castillo de Barcience, en …\n  :context_section_description     =&gt; \"Hacia 1427 contrajo matrimonio con Leono…\n  :hierarchical_section_title      =&gt; \"Juan de Silva y Meneses / Biografía / Pr…\n  :page_url                        =&gt; \"https://es.wikipedia.org/wiki/Juan_de_Si…\n  :attribution_passes_lang_id      =&gt; false\n  :section_title                   =&gt; \"Primer matrimonio y ascenso en la Corte …\n  :is_main_image                   =&gt; false\n  :image_url                       =&gt; \"http://upload.wikimedia.org/wikipedia/co…\n  :page_title                      =&gt; \"Juan de Silva y Meneses\"\n  :original_width                  =&gt; 960\n  :page_changed_recently           =&gt; false\n  :caption_attribution_description =&gt; \"Castle of Barcience, near Maqueda, in th…\n  :context_page_description        =&gt; \"Juan de Silva y Meneses, noble y cortesa…\n  :original_height                 =&gt; 1280\n  :language                        =&gt; \"es\"\n  :mime_type                       =&gt; String15(\"image/jpeg\")\n  :caption_alt_text_description    =&gt; missing"
  },
  {
    "objectID": "04-text-IR.html#creación-del-modelo-de-preprocesamiento-y-tokenización-de-texto",
    "href": "04-text-IR.html#creación-del-modelo-de-preprocesamiento-y-tokenización-de-texto",
    "title": "Búsqueda de Texto Completo",
    "section": "Creación del modelo de preprocesamiento y tokenización de texto",
    "text": "Creación del modelo de preprocesamiento y tokenización de texto\nAhora si podemos comenzar con la parte de procesamiento de información textual, para esto estaremos usando nuestro paquete TextSearch.\n\ntextmodel = TextConfig()\nDict(f =&gt; getfield(textmodel, f) for f in fieldnames(typeof(textmodel)))\n\nDict{Symbol, Any} with 14 entries:\n  :group_usr       =&gt; false\n  :slist           =&gt; Skipgram[]\n  :collocations    =&gt; 0\n  :del_diac        =&gt; true\n  :del_dup         =&gt; false\n  :del_punc        =&gt; false\n  :lc              =&gt; true\n  :nlist           =&gt; Int8[1]\n  :mark_token_type =&gt; true\n  :group_url       =&gt; true\n  :qlist           =&gt; Int8[]\n  :tt              =&gt; IdentityTokenTransformation()\n  :group_emo       =&gt; false\n  :group_num       =&gt; true\n\n\nEsta estructura contiene indicaciones necesarias para preprocesar y tokenizar el texto\n\ntextmodel\n\nTextConfig(true, false, false, true, true, false, false, true, 0, true, Int8[], Int8[1], Skipgram[], IdentityTokenTransformation())\n\n\nPara crear un índice invertido es necesario obtener un vocabulario del texto; utilizaremos para esto el campo content_page_description:\n\nvoc = Vocabulary(textmodel, D.context_page_description)\n\n\nvocabulary:  58%|███████████████████████                 |  ETA: 0:00:09\nvocabulary:  75%|██████████████████████████████▎         |  ETA: 0:00:08\nvocabulary: 100%|████████████████████████████████████████| Time: 0:00:24\n\n\n\n\nVocabulary{TokenLookup}(TokenLookup(), TextConfig(true, false, false, true, true, false, false, true, 0, true, Int8[], Int8[1], Skipgram[], IdentityTokenTransformation()), [\"quintanilla\", \"de\", \"riofresno\", \"es\", \"una\", \"localidad\", \"espanola\", \"y\", \"tambien\", \"entidad\"  …  \"tayatos\", \"tayasus\", \"sainos\", \"tuncos\", \"puercos\", \"baquiros\", \"pecari\", \"infravalorando\", \"sociologismo\", \"bauta\"], Int32[46, 1387148, 7, 221973, 185007, 11552, 7096, 455246, 32727, 1248  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 2], Int32[40, 169026, 7, 134173, 110192, 10618, 6108, 142257, 28097, 1164  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], Dict{String, UInt32}(\"reagruparse\" =&gt; 0x0001ad67, \"atharratze\" =&gt; 0x0002afe5, \"sirviesen\" =&gt; 0x000226ab, \"solene\" =&gt; 0x0000f0bf, \"elongado\" =&gt; 0x0003878d, \"devorar\" =&gt; 0x00028525, \"inhiben\" =&gt; 0x0000a2ec, \"qajar\" =&gt; 0x00015ad6, \"propagarian\" =&gt; 0x0003425e, \"allaudiens\" =&gt; 0x00039fae…), 173617)\n\n\nVamos a intentar visualizar convirtiendo nuestra estructura en una tabla:\n\ntable(voc, DataFrame)\n\n295333×3 DataFrame295308 rows omitted\n\n\n\nRow\ntoken\nndocs\noccs\n\n\n\nString\nInt32\nInt32\n\n\n\n\n1\nquintanilla\n40\n46\n\n\n2\nde\n169026\n1387148\n\n\n3\nriofresno\n7\n7\n\n\n4\nes\n134173\n221973\n\n\n5\nuna\n110192\n185007\n\n\n6\nlocalidad\n10618\n11552\n\n\n7\nespanola\n6108\n7096\n\n\n8\ny\n142257\n455246\n\n\n9\ntambien\n28097\n32727\n\n\n10\nentidad\n1164\n1248\n\n\n11\nlocal\n2269\n2435\n\n\n12\nmenor\n2411\n2615\n\n\n13\n,\n156540\n917053\n\n\n⋮\n⋮\n⋮\n⋮\n\n\n295322\ntayasuidos\n1\n1\n\n\n295323\ntaguas\n1\n1\n\n\n295324\ntayatos\n1\n1\n\n\n295325\ntayasus\n1\n1\n\n\n295326\nsainos\n1\n1\n\n\n295327\ntuncos\n1\n1\n\n\n295328\npuercos\n1\n1\n\n\n295329\nbaquiros\n1\n1\n\n\n295330\npecari\n1\n1\n\n\n295331\ninfravalorando\n1\n1\n\n\n295332\nsociologismo\n1\n1\n\n\n295333\nbauta\n1\n2\n\n\n\n\n\n\n\nDistribución del vocabulario (Ley de Zipf)\nVamos a ver su distribución (frecuencia por token o palabra)\n\n\np = plot(y=sort(ndocs(voc), rev=true)[1:1000], type=:scatter)\ndisplay(p)\np = plot(y=sort(ndocs(voc), rev=true), type=:scatter)\np.layout.title = \"Ley de Zipf\"\np.layout.xaxis.type = \"log\"\np.layout.yaxis.type = \"log\"\np\n\n\n\n\n\n\n\nLa distribución es tipo ley de potencia, Ley de Zipf; el vocabulario es grande, y la cola de la distribución es enorme, lo cual quiere decir que pocas palabras tienen mucha frecuencia y muchísimas aparecen poco.\nLas palabras muy frecuentes serán artículos, conjunciones, preprocisiones, etc. Palabras que muchas veces no abonan información semántica importante para la búsqueda. A estas palabras se les llama stopwords, y muchas veces podrían estar inyectando información inútil a nuestro modelo.\nPor otra parte, dado el tipo de colección, la cola larga de la distribución podría indicar que hay temas muy especializados y deberíamos preservar ese vocabulario. Por razones de simplificación y ahorro de recursos, vamos a suponer que los temas muy especializados, se saldrán de nuestras posibles consultas. Por lo que podemos filtrar el vocabulario como sigue.\n\n\ndisplay(vocsize(voc))\nvoc = filter_tokens(voc) do t\n  3 &lt;= t.ndocs &lt;= 9_000\nend\nvocsize(voc)\n\n295333\n\n\n105940\n\n\nNuestro vocabulario ahora es más pequeño y los vectores que generará serán menos dispersos. En una aplicación se debe valorar que y hasta donde este filtrado debe hacerse, ya que impactará en diferentes formas a nuestras aplicaciones."
  },
  {
    "objectID": "04-text-IR.html#sobre-el-pesado-de-términos",
    "href": "04-text-IR.html#sobre-el-pesado-de-términos",
    "title": "Búsqueda de Texto Completo",
    "section": "Sobre el pesado de términos",
    "text": "Sobre el pesado de términos\nYa se ha mencionado que un índice invertido es, fundamentalmente, la representación dispersa \\(W^*\\) de la matriz de pesos \\(W_{m,n}\\) de términos vs documentos, con acceso eficiente por filas. Teniendo en cuenta que el número términos por documento con respecto al vocabulario completo es muy baja, dicha representación puede llegar a ser muy eficiente. Es entendible que dependiendo de la colección, los términos podrían llegar a ser más o menos importantes, esto se controla mediante el pesado de términos, que serán finalmente las componentes que se multiplicarán cuando se evalue (de manera explícita o implícita) el producto punto entre consulta y documentos. A continuación se mencionan algunas estrategías de pesados:\n\nBinario: Los pesos toman 2 valores, 1 cuando el término ocurren en el documento y 0 cuando no lo hace.\nFrecuencia local: Se usa la frecuencia del término dentro del documento, útil cuando se sabe que la información local (de la instancia o documento) es dominante.\nFrecuencia global: Se usa la frecuencia del término en la colección, útil cuando la información global es más importante que la información de cada instancia.\n\nEs posible ver dos tendencias naturales, pesado local y pesado global, además de uso de estadísticas de ocurrencias para asignar pesos. Habrá problemas que se beneficien de tener pesos tanto locales como globales, y por tanto usar ambos es una estrategía común. Así mismo, es necesario hacer notar que el uso de frecuencias es desaconsejable ya que dependerán del tamaño de los documentos, y esto será claramente un problema si los documentos son de tamaños diferentes. Por tanto, una solución es desasociar del tamaño del documento, por ejemplo, usando probabilidades u otras técnicas que remuevan la magnitud.\n\nFrecuencia de término (TF)\nPara el pesado local, es posible realizar diferentes normalizaciones, por ejemplo, la probabilidad empírica de que un término ocurra en un documento \\(d\\). \\[ tp(t, d) = \\frac{\\textsf{occs}(t, d)}{\\sum_{t' \\in d} \\textsf{occs}(t', d)} \\] donde \\(\\textsf{occs}(t, d)\\) es el número de ocurrencias de \\(t\\) en el documento \\(d\\).\nTambién es común usar la máxima frecuencia como normalizador \\[\\textsf{TF}(t, d) = \\frac{\\textsf{occs}(t, d)}{\\max_{t' \\in d} \\textsf{occs}(t', d)} \\] de hecho, esta es la forma de la frecuencia de término (TF), uno de los pesados locales más usados.\n\n\nFrecuencia de documento inversa (\\(\\textsf{IDF}\\))\nEl pesado global puede realizarse por medio de la probabilidad de que un término \\(t\\) ocurra pero ahora en el corpus completo \\(C\\) \\[ \\textsf{DF}(t, C) = \\frac{\\textsf{ndocs}(t, C)}{N}\\]\ndonde \\(\\textsf{ndocs}(t, C)\\) es el número de documentos que contienen a \\(t\\) en el corpus \\(C\\), y \\(N\\) es el número de documentos en la colección.\nYa que las colecciones pueden ser muy grandes, es posible que aún en su forma de probabilidad este número sea o muy grande o muy pequeño (Ley de Zipf, ver más adelante). Es por esto que suele modificarse la magnitud usando \\(\\log\\), en particular, se puede calcular el llamado inverse document frequency como sigue:\n\\[\\textsf{IDF}(t, C) = \\log \\frac{N}{\\textsf{ndocs}(t, C)} \\]\nEsto hace que las palabras con pocas apariciones en la colección tengan un peso alto, ya que se desea contrarestar la información local.\n\n\nCombinando pesado local y global - \\(\\textsf{TFIDF}\\)\nLa combinación de pesado local y global es comúnmente realizada por la multiplicación de ambas. En el caso de TF e \\(\\textsf{IDF}\\), su combinación se encuentra entre los métodos más aceptados para pesar términos. En este caso se debe tener en cuenta que \\(\\textsf{TF}(t, d)\\) varia entre 0 y 1 mientras que \\(\\textsf{IDF}(t, C)\\) entre 0 y \\(\\log N\\). La magnitud de DF se puede reducir mediante el uso de diferentes bases del logaritmo (factor) o haciendolo como el cociente de \\(\\textsf{IDF}(t, C) / \\log N\\) para hacerlo variar entre 0 y 1. Sin embargo, la manera más aceptada es\n\\[\\textsf{TFIDF}(t, d, C) = \\textsf{TF}(t, d) \\times \\textsf{IDF}(t, C)\\]\npero es importante conocer que este pesado dará importancia al peso global, dado su rango de valores.\n\n\nCreación de una bolsa de palabras (pesado binario)\n\nlet text = D.context_page_description[1]\n  display(text)\n  bagofwords(voc, text)\nend\n\n\"Juan de Silva y Meneses, noble y cortesano castellano, I conde de Cifuentes y I señor de Montemayor del Río.\"\n\n\nDict{UInt32, Int32} with 11 entries:\n  0x000002a1 =&gt; 1\n  0x000002a4 =&gt; 1\n  0x0000029d =&gt; 1\n  0x0000029f =&gt; 1\n  0x000002a5 =&gt; 1\n  0x000002a0 =&gt; 1\n  0x000002a2 =&gt; 2\n  0x000002a6 =&gt; 1\n  0x000002a3 =&gt; 1\n  0x00000193 =&gt; 1\n  0x0000029e =&gt; 1\n\n\n\n\nCreación de un modelo TFIDF\nEl modelo vectorial intenta poner pesos\n\nvmodel = VectorModel(IdfWeighting(), TfWeighting(), voc)\n\n{VectorModel\n    global_weighting: TextSearch.IdfWeighting()\n    local_weighting: TextSearch.TfWeighting()\n    vocsize: 105940\n    trainsize=173617\n    maxoccs=14551                                    \n}\n\n\nAhora podemos observar el vocabulario, ordenado por su peso TFIDF\n\nsort!(table(vmodel, DataFrame), :weight)\n\n105940×4 DataFrame105915 rows omitted\n\n\n\nRow\ntoken\nndocs\noccs\nweight\n\n\n\nString\nInt32\nInt32\nFloat32\n\n\n\n\n1\nlugar\n8905\n9965\n4.28507\n\n\n2\nsin\n8903\n9799\n4.2854\n\n\n3\nfueron\n8775\n10516\n4.30629\n\n\n4\nespanol\n8757\n9492\n4.30925\n\n\n5\ncerca\n8591\n9003\n4.33686\n\n\n6\nmundo\n8526\n10381\n4.34782\n\n\n7\nhistoria\n8497\n10550\n4.35273\n\n\n8\ncuando\n8444\n9576\n4.36176\n\n\n9\nsido\n8405\n9320\n4.36843\n\n\n10\nbajo\n8378\n9348\n4.37308\n\n\n11\nunidos\n8350\n11215\n4.37791\n\n\n12\ncanton\n8290\n8954\n4.38831\n\n\n13\nsiendo\n8193\n8763\n4.40529\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n105929\nslack\n3\n3\n15.5982\n\n\n105930\nsanclemente\n3\n3\n15.5982\n\n\n105931\ntridacna\n3\n3\n15.5982\n\n\n105932\ntimol\n3\n3\n15.5982\n\n\n105933\nliesegang\n3\n5\n15.5982\n\n\n105934\nbeleno\n3\n3\n15.5982\n\n\n105935\npicoteo\n3\n3\n15.5982\n\n\n105936\nmistericas\n3\n3\n15.5982\n\n\n105937\nurcuqui\n3\n3\n15.5982\n\n\n105938\namorreo\n3\n3\n15.5982\n\n\n105939\nlehr\n3\n4\n15.5982\n\n\n105940\npornograficos\n3\n4\n15.5982\n\n\n\n\n\n\nLa función vectorize_corpus codificará una colección de textos en una colección de vectores dispersos:\n\nX = vectorize_corpus(vmodel, D.context_page_description)\n\n173617-element Vector{Dict{UInt32, Float32}}:\n Dict(0x000002a0 =&gt; 0.35631496, 0x000002a1 =&gt; 0.2550329, 0x000002a2 =&gt; 0.31910866, 0x000002a4 =&gt; 0.39598918, 0x0000029d =&gt; 0.16277333, 0x0000029f =&gt; 0.36310205, 0x000002a3 =&gt; 0.22391844, 0x0000029e =&gt; 0.28939986, 0x000002a6 =&gt; 0.3751071, 0x000002a5 =&gt; 0.24340351…)\n Dict(0x0000031d =&gt; 0.1934031, 0x0000031a =&gt; 0.058253493, 0x0000033a =&gt; 0.11065471, 0x0000030a =&gt; 0.1961731, 0x00000318 =&gt; 0.094530195, 0x00000328 =&gt; 0.047937825, 0x00000310 =&gt; 0.07686158, 0x000002fd =&gt; 0.32971355, 0x00000313 =&gt; 0.058193102, 0x00000331 =&gt; 0.11524162…)\n Dict(0x0000033e =&gt; 0.5663953, 0x0000033b =&gt; 0.2978877, 0x0000033f =&gt; 0.3444223, 0x00000342 =&gt; 0.3130285, 0x0000033d =&gt; 0.44079337, 0x00000251 =&gt; 0.1741738, 0x0000033c =&gt; 0.38627768)\n Dict(0x000003b6 =&gt; 0.16771603, 0x000003ad =&gt; 0.1643711, 0x000003a1 =&gt; 0.26653925, 0x000003ba =&gt; 0.13888754, 0x000003af =&gt; 0.23115146, 0x000001af =&gt; 0.07714929, 0x000003b8 =&gt; 0.28169093, 0x000003a8 =&gt; 0.17456678, 0x0000012c =&gt; 0.077427134, 0x000003b1 =&gt; 0.1569611…)\n Dict(0x000003f6 =&gt; 0.09136061, 0x00000072 =&gt; 0.065044604, 0x000003fc =&gt; 0.046637222, 0x00000409 =&gt; 0.06269452, 0x00000418 =&gt; 0.117511116, 0x00000006 =&gt; 0.058549114, 0x00000400 =&gt; 0.08742988, 0x00000402 =&gt; 0.10178582, 0x00000328 =&gt; 0.05072841, 0x00000427 =&gt; 0.17176506…)\n Dict(0x0000043f =&gt; 0.256909, 0x00000446 =&gt; 0.2215901, 0x00000444 =&gt; 0.2073676, 0x0000043d =&gt; 0.18100917, 0x0000043a =&gt; 0.6825381, 0x00000440 =&gt; 0.3775326, 0x00000441 =&gt; 0.37202036, 0x0000017f =&gt; 0.13943286, 0x00000016 =&gt; 0.1671388, 0x0000012a =&gt; 0.12233072…)\n Dict(0x00000466 =&gt; 0.4219556, 0x0000046d =&gt; 0.32538906, 0x0000046e =&gt; 0.5000652, 0x00000476 =&gt; 0.24302265, 0x00000473 =&gt; 0.3512539, 0x00000474 =&gt; 0.19093455, 0x00000475 =&gt; 0.28764993, 0x0000046a =&gt; 0.40542862)\n Dict(0x000004d2 =&gt; 0.17229286, 0x000004df =&gt; 0.11932593, 0x0000035a =&gt; 0.12201269, 0x000002d4 =&gt; 0.13889205, 0x000004dc =&gt; 0.15098058, 0x000004c6 =&gt; 0.07423435, 0x000004c5 =&gt; 0.0764306, 0x000004d0 =&gt; 0.09217965, 0x000004d3 =&gt; 0.10771819, 0x000004cf =&gt; 0.1364518…)\n Dict(0x00000539 =&gt; 0.13324802, 0x0000053d =&gt; 0.14524771, 0x00000520 =&gt; 0.12222228, 0x00000540 =&gt; 0.090998776, 0x00000546 =&gt; 0.14642914, 0x00000073 =&gt; 0.04641057, 0x0000052c =&gt; 0.08691394, 0x0000054b =&gt; 0.13224106, 0x00000535 =&gt; 0.10330265, 0x000004a8 =&gt; 0.04648163…)\n Dict(0x000001ad =&gt; 0.050600946, 0x000004c6 =&gt; 0.04663893, 0x000005cb =&gt; 0.06385808, 0x000004c5 =&gt; 0.04801875, 0x00000510 =&gt; 0.042771712, 0x000005c6 =&gt; 0.07367458, 0x000005b1 =&gt; 0.046566512, 0x000005a6 =&gt; 0.4826828, 0x000005bc =&gt; 0.046445776, 0x000005cc =&gt; 0.0659867…)\n ⋮\n Dict(0x00005ad0 =&gt; 0.68701476, 0x000000b8 =&gt; 0.37084287, 0x000001ea =&gt; 0.41068274, 0x00000253 =&gt; 0.47098407)\n Dict(0x00007c26 =&gt; 0.16033074, 0x00002075 =&gt; 0.14745493, 0x000070fa =&gt; 0.1816467, 0x00000073 =&gt; 0.06868537, 0x000018ea =&gt; 0.3030047, 0x000009a0 =&gt; 0.117882535, 0x00000ffd =&gt; 0.117788896, 0x00000af5 =&gt; 0.10833342, 0x000007c4 =&gt; 0.23731005, 0x0000045c =&gt; 0.18847099…)\n Dict(0x0000014d =&gt; 0.43054065, 0x0000049d =&gt; 0.4557649, 0x0000105b =&gt; 0.5725784, 0x00000bca =&gt; 0.528268)\n Dict(0x0000243f =&gt; 0.112064555, 0x00000072 =&gt; 0.078065656, 0x00010746 =&gt; 0.3553037, 0x000003a9 =&gt; 0.12868047, 0x00005e91 =&gt; 0.11596028, 0x000002b1 =&gt; 0.051812276, 0x0000af3d =&gt; 0.14707741, 0x000046d6 =&gt; 0.10395091, 0x0000183e =&gt; 0.101866335, 0x000017bd =&gt; 0.098967955…)\n Dict(0x00000757 =&gt; 0.17723022, 0x00001a71 =&gt; 0.19661337, 0x00000107 =&gt; 0.14149822, 0x00008a49 =&gt; 0.36934438, 0x00000206 =&gt; 0.15591621, 0x0000e1e6 =&gt; 0.44328472, 0x00000db3 =&gt; 0.16429412, 0x0001411e =&gt; 0.41645083, 0x000004e2 =&gt; 0.18127087, 0x00000493 =&gt; 0.14856973…)\n Dict(0x000002fb =&gt; 0.29093155, 0x0000000c =&gt; 0.27121538, 0x000029bd =&gt; 0.44428107, 0x000015d7 =&gt; 0.3655619, 0x0000163b =&gt; 0.4000444, 0x000015ac =&gt; 0.38382664, 0x0000032c =&gt; 0.24423769, 0x00001104 =&gt; 0.3791693)\n Dict(0x000001d9 =&gt; 0.124599986, 0x000003a1 =&gt; 0.13276498, 0x00000b8c =&gt; 0.17564403, 0x000035e3 =&gt; 0.24982437, 0x0000f867 =&gt; 0.35475093, 0x0000305a =&gt; 0.33805984, 0x00003f00 =&gt; 0.27542424, 0x0000133d =&gt; 0.15174644, 0x00001732 =&gt; 0.19752021, 0x00003902 =&gt; 0.19542225…)\n Dict(0x00003a8f =&gt; 0.23253304, 0x000002c0 =&gt; 0.14765628, 0x0000062d =&gt; 0.20969635, 0x0000414a =&gt; 0.2766713, 0x000040fa =&gt; 0.24989903, 0x00002a19 =&gt; 0.22518638, 0x000087e3 =&gt; 0.2994466, 0x00006f04 =&gt; 0.49979806, 0x00000b90 =&gt; 0.15838923, 0x00002c89 =&gt; 0.24207474…)\n Dict(0x0000316f =&gt; 0.110937715, 0x00001b17 =&gt; 0.11062889, 0x00011cdd =&gt; 0.14243864, 0x000007d2 =&gt; 0.084642306, 0x00001168 =&gt; 0.1630529, 0x00000c08 =&gt; 0.08548675, 0x000032a8 =&gt; 0.118538655, 0x00003650 =&gt; 0.13023199, 0x00002836 =&gt; 0.104743704, 0x00001dc2 =&gt; 0.09329269…)"
  },
  {
    "objectID": "04-text-IR.html#búsqueda-por-fuerza-bruta",
    "href": "04-text-IR.html#búsqueda-por-fuerza-bruta",
    "title": "Búsqueda de Texto Completo",
    "section": "Búsqueda por fuerza bruta",
    "text": "Búsqueda por fuerza bruta\nVamos a utilizar estos vectores para realizar búsquedas; para esto usaremos el paquete SimilaritySearch y varias de sus estructuras y funciones.\n\nn = 10^4\ndb, queries = VectorDatabase(X[1:n]), VectorDatabase(X[n+1:n+100])\ndist = CosineDistance()\nS = ExhaustiveSearch(; db, dist)\nctx = GenericContext()\n\nGenericContext{KnnSorted}(0, true, InformativeLog(1.0, Base.RefValue{Float64}(0.0), Base.Threads.SpinLock(0)))\n\n\nAhora podemos buscar bloques de consultas, la siguiente instrucción busca 10 vecinos cercanos de queries en la base de datos db (usando el índice S y su contexto de búsqueda ctx).\n\n@time knns = searchbatch(S, ctx, queries, 10)\n\n  1.828086 seconds (2.07 M allocations: 139.108 MiB, 26.84% gc time, 241.29% compilation time)\n\n\n10×100 Matrix{IdWeight}:\n IdWeight(0x00000b5f, 0.484999)  …  IdWeight(0x00000d31, 0.806195)\n IdWeight(0x00002282, 0.542134)     IdWeight(0x000000d1, 0.824249)\n IdWeight(0x00001ed0, 0.54688)      IdWeight(0x00000767, 0.842457)\n IdWeight(0x0000117b, 0.588585)     IdWeight(0x0000169b, 0.850239)\n IdWeight(0x00000d1d, 0.658771)     IdWeight(0x00001e2f, 0.854055)\n IdWeight(0x00001a58, 0.696891)  …  IdWeight(0x0000095e, 0.865598)\n IdWeight(0x00001e38, 0.714155)     IdWeight(0x000014fa, 0.867576)\n IdWeight(0x00001c2d, 0.740831)     IdWeight(0x00000aef, 0.870025)\n IdWeight(0x00001c1b, 0.760621)     IdWeight(0x0000257f, 0.89476)\n IdWeight(0x00001c7c, 0.772887)     IdWeight(0x00001bd4, 0.90257)\n\n\nEs interesante ver el costo y ejecutarlo al menos dos veces para remover el tiempo de compilación de Julia.\n\nObservación de resultados\nA continuación veremos que tipo de cosas consultamos y que tipos de cosas se recuperarón\n\nqID = 100\nr = D[10_000 + qID, :]\nDict(pairs(r))\n\nDict{Symbol, Any} with 19 entries:\n  :image_url_sha256                =&gt; \"5466614e57c876674ad5347395651c1132f592b4…\n  :ID                              =&gt; String15(\"00000_0211707\")\n  :caption_reference_description   =&gt; \"Vista posterior de un Volkswagen Brasili…\n  :context_section_description     =&gt; \"En la mayoría de los mercados de América…\n  :hierarchical_section_title      =&gt; \"Volkswagen Brasilia / Primeros años\"\n  :page_url                        =&gt; \"https://es.wikipedia.org/wiki/Volkswagen…\n  :attribution_passes_lang_id      =&gt; false\n  :section_title                   =&gt; \"Primeros años\"\n  :is_main_image                   =&gt; false\n  :image_url                       =&gt; \"https://upload.wikimedia.org/wikipedia/c…\n  :page_title                      =&gt; \"Volkswagen Brasilia\"\n  :original_width                  =&gt; 328\n  :page_changed_recently           =&gt; false\n  :caption_attribution_description =&gt; \"Português: Volkswagen Brasília Português…\n  :context_page_description        =&gt; \"El Volkswagen Brasilia fue un automóvil …\n  :original_height                 =&gt; 245\n  :language                        =&gt; \"es\"\n  :mime_type                       =&gt; String15(\"image/jpeg\")\n  :caption_alt_text_description    =&gt; missing\n\n\nAhora visualizaremos usando HTML empotrado (ver Cobweb que es el paquete que estamos usando para este punto). La consulta se ve como sigue:\n\n\nh.table(\n  h.tr(\n    h.td(h.img(src=r.image_url, alt=r.page_title, width=240), style=\"width: 20%;\"),\n    h.td(r.context_page_description)\n  )\n)\n\n\n\n\n\nEl Volkswagen Brasilia fue un automóvil producido entre 1973 y 1982 por Volkswagen do Brasil. Fue diseñado para combinar la robustez del Volkswagen Sedán, un auto que ya estaba consagrado, con la comodidad de un auto más moderno con mayor espacio interior. Este nombre es un homenaje a la entonces ciudad moderna, Brasilia, la capital brasileña que había sido fundada 13 años antes, este automóvil solo salió a la venta en México y Brasil. Su nomenclatura interna es denominada Tipo 321. Su tipo de carrocería está en discusión, debido a su apariencia de mini-vagoneta por lo que popularmente se le conoce como la Brasilia, en vez de el Brasilia.\n\n\n\n\n\nAhora los resultados recuperados:\n\nchildren = []\nfor p in view(knns, :, qID)\n  r = D[p.id, [:image_url, :page_url, :page_title]]\n  push!(children,\n    h.div(style=\"display: inline-block; margin-left: 0.25cm;\",\n      h.img(src=r.image_url, alt=r.page_title, width=160), h.br(),\n      h.a(r.page_title, href=r.page_url)\n    )\n  )\nend\n\nres = h.div(children)\n\nVolkswagen Polo IIIVolkswagen TouranRobustez (evolución)Turbo inyección directaVolkswagen T-CrossVicepresidente de BrasilFord VersaillesLuís Roberto BarrosoSEAT Toledo IScania\n\n\nVamos a ver el histograma de distancias, que nos puede decir mucho sobre la dificultad de un problema de búsqueda.\n\np = plot()\np.layout.title.text = \"knn distance histogram\"\np.histogram(x=convert.(Float32, view(knns, 10, :)))"
  },
  {
    "objectID": "04-text-IR.html#búsqueda-con-índice",
    "href": "04-text-IR.html#búsqueda-con-índice",
    "title": "Búsqueda de Texto Completo",
    "section": "Búsqueda con índice",
    "text": "Búsqueda con índice\n\nG = WeightedInvertedFile(vocsize(vmodel))\ngctx = InvertedFileContext()\n@time append_items!(G, gctx, VectorDatabase(X))\n\nLOG append_items! InvertedFiles.WeightedInvertedFile{Nothing, SimilaritySearch.AdjacencyLists.AdjacencyList{SimilaritySearch.AdjacencyLists.IdWeight}} sp=0 ep=173617 n=173617 2025-10-23T12:12:37.298\n  0.795982 seconds (558.69 k allocations: 152.435 MiB, 41.39% compilation time)\n\n\n{InvertedFiles.WeightedInvertedFile{Nothing, SimilaritySearch.AdjacencyLists.AdjacencyList{SimilaritySearch.AdjacencyLists.IdWeight}} vocsize=105940, n=173617}\n\n\n\n@time knns = searchbatch(G, gctx, VectorDatabase(X[1000:1100]), 10)\n\n  0.642084 seconds (460.45 k allocations: 30.288 MiB, 78.24% compilation time)\n\n\n10×101 Matrix{IdWeight}:\n IdWeight(0x000003e8, 2.58442f-7)  …  IdWeight(0x0000044c, -7.05477f-8)\n IdWeight(0x0000081e, 2.58442f-7)     IdWeight(0x00020419, 0.792734)\n IdWeight(0x0000419b, 2.58442f-7)     IdWeight(0x0002a472, 0.825216)\n IdWeight(0x000131b6, 2.58442f-7)     IdWeight(0x00029a1e, 0.83384)\n IdWeight(0x00015c7d, 2.58442f-7)     IdWeight(0x0002663c, 0.834193)\n IdWeight(0x00017ba6, 2.58442f-7)  …  IdWeight(0x00015a01, 0.839952)\n IdWeight(0x0001fc44, 2.58442f-7)     IdWeight(0x000276e4, 0.842087)\n IdWeight(0x00029170, 2.58442f-7)     IdWeight(0x0000372c, 0.842452)\n IdWeight(0x0002a423, 2.58442f-7)     IdWeight(0x00015e07, 0.843829)\n IdWeight(0x00015875, 0.607854)       IdWeight(0x0000fd81, 0.845772)\n\n\n\n\nqID = 13\nr = D[1000+qID-1, :]\n\nh.table(\n  h.tr(\n    h.td(h.img(src=r.image_url, alt=r.page_title, width=160)),\n    h.td(r.context_page_description)\n  )\n)\n\n\n\n\n\nLa romerina, también nombrada como romero macho, es una especie perteneciente a la familia de las cistáceas.\n\n\n\n\n\n\n\nchildren = []\nfor p in view(knns, :, qID)\n  r = D[p.id, [:image_url, :page_url, :page_title]]\n  push!(children,\n    h.div(style=\"display: inline-block; margin-left: 0.25cm;\",\n      h.img(src=r.image_url, alt=r.page_title, width=160), h.br(),\n      h.a(r.page_title, href=r.page_url)\n    )\n  )\nend\n\nres = h.div(children)\n\nCistus clusiiTuberaria guttataCistus osbeckiifoliusHelianthemum nummulariumHelianthemum croceumFumana procumbensHelianthemum glomeratumHelianthemum apenninumHelianthemum apenninumCistus monspeliensis\n\n\n\np = plot()\np.layout.title.text = \"knn distance histogram - indexed\"\np.histogram(x=convert.(Float32, view(knns, 10, :)))"
  },
  {
    "objectID": "04-text-IR.html#consultas-libres",
    "href": "04-text-IR.html#consultas-libres",
    "title": "Búsqueda de Texto Completo",
    "section": "Consultas libres",
    "text": "Consultas libres\n\n@time res = search(G, gctx, vectorize(vmodel, \"Benito Juarez\"), knnqueue(gctx, 10))\n\n  0.155625 seconds (66.91 k allocations: 4.501 MiB, 99.91% compilation time)\n\n\nKnnSorted{Vector{IdWeight}}(IdWeight[IdWeight(0x00004af1, 0.11199722f0), IdWeight(0x0002010c, 0.32738084f0), IdWeight(0x00020d33, 0.48804796f0), IdWeight(0x000251d0, 0.52739954f0), IdWeight(0x0001bf3a, 0.52976495f0), IdWeight(0x0001e561, 0.5349007f0), IdWeight(0x00021e55, 0.5407868f0), IdWeight(0x00012313, 0.56588054f0), IdWeight(0x00007a2e, 0.57835376f0), IdWeight(0x00006ee4, 0.6067635f0)], 1, 10, 10, 460, 0)\n\n\n\n\nchildren = []\nfor p in viewitems(res)\n  r = D[p.id, [:image_url, :page_url, :page_title]]\n  push!(children,\n    h.div(style=\"display: inline-block; margin-left: 0.25cm;\",\n      h.img(src=r.image_url, alt=r.page_title, width=160), h.br(),\n      h.a(r.page_title, href=r.page_url)\n    )\n  )\nend\n\nres = h.div(children)\n\nTlacotepec de Benito JuárezBenito Juárez (Michoacán)Sierra de Juárez (Oaxaca)Municipio de Juárez (Chihuahua)Benito Juárez (Ciudad de México)Benito JuárezRestauración republicana en MéxicoZapata (estación)Iglesia de San Benito de la CalzadaSan Juan Bautista (California)\n\n\n\nEjercicios\n\nCree un minibuscador sobre WIT que acepte consultas sobre los titulos y muestre 10 resultados similares; haga que se visualice la imagen y el context_page_description.\nCree una tabla de contenidos relacionados usando los titulos.\n\nEjemplo de solución: https://colab.research.google.com/drive/11WXBWIQgTrEsoHMwJErhaqJrIVVKwCPF?usp=sharing https://colab.research.google.com/drive/11WXBWIQgTrEsoHMwJErhaqJrIVVKwCPF?usp=sharing"
  },
  {
    "objectID": "05-metric-IR.html",
    "href": "05-metric-IR.html",
    "title": "Búsqueda en espacios métricos",
    "section": "",
    "text": "Introducción\n  Marco teórico\n  \n  \\(k\\) vecinos cercanos\n  \n  Sobre la dimensión intrínseca\n  Búsqueda aproximada\n  \n  Esquemas de búsqueda de \\(k\\)-vecinos cercanos en gráficas\n  \n  Bibliografía\n  Ejemplo de uso con SimilaritySearch\n  \n  Descargando los datos\n  \n  Búsqueda por fuerza bruta en imágenes\n  \n  Ejercicios\n  \n  Búsqueda con Texto\n  \n  Ejercicios\n  \n  Búsqueda Multimodal\n  Búsqueda con índice\n  \n  Ejercicios\nEl script para crear las representaciones vectoriales es el siguiente https://colab.research.google.com/drive/1UNzBe4kAE0KA_xRcmhORFvCPoHZeO_UB?usp=sharing\nLos ejercicios de esta unidad estan en colab https://colab.research.google.com/drive/103qHTT_gyOiga8wjsUoWNCB5i__KiOEl?usp=sharing"
  },
  {
    "objectID": "05-metric-IR.html#introducción",
    "href": "05-metric-IR.html#introducción",
    "title": "Búsqueda en espacios métricos",
    "section": "Introducción",
    "text": "Introducción\nLos algoritmos de búsqueda son centrales en múltiples áreas de las ciencias de la computación; en particular en la recuperación de información. Este problema consiste en identificar rápidamente en una colección objetos que son cercanos a un ejemplo dado, este problema fue definido con respecto a documentos en la Unidad 2. En la presente unidad se generalizará el concepto.\nLa cercanía o similitud es representada mediante una función de distancia que da una perspectiva geométrica o espacial al problema. Una de las operaciones más importantes en la búsqueda por similitud es la recuperación de \\(k\\) vecinos cercanos que consiste en encontrar los \\(k\\) elementos más cercanos de una base de datos a una consulta dada.\nEl problema consiste en preprocesar una colección de datos, bajo alguna función de semejanza, para que la identificación de los objetos cercanos a una consulta pueda hacerse en tiempo que no dependa linealmente del tamaño de la colección. En otras palabras, que no sea necesario revisar todos los elementos de la base de datos para responder la consulta. La búsqueda de los \\(k\\)-vecinos cercanos tiene aplicaciones en diferentes áreas, como parte operativa de algoritmos de agrupamiento [@SS2021] o como parte de la aceleración de dichos algoritmos [@YCC2020; @SKL2011]. En procesamiento de lenguaje natural, la técnica es usada para diferentes objetivos, tal es el caso de recuperación de argumentos [@WPAA2017], descubrimiento de estructuras semánticas [@DS2020], búsqueda semántica [@SPA2019; @FH2017], entre otras. En problemas de clasificación, el método de \\(k\\) vecinos cercanos ha sido usado como uno de los métodos más simples y populares, y a la vez, efectivo [@GCVR2018; @OTGMM2020]. El cálculo de grafos de todos los vecinos cercanos es uno de los componentes de las técnicas de reducción de dimensión no-lineales, como UMAP [@MHM2018], TriMap [@AW2019], o t-SNE [@VMH2018], además de las alternativas clásicas [@LV2017]. El proceso de reducción de dimensión es usado para incrementar el desempeño de algoritmos de aprendizaje computacional, así como en el proceso de análisis de los datos. Las dimensiones 2 y 3 nos permiten visualizar información de manera efectiva, y por tanto, una proyección fiel en baja dimensión siempre será de utilidad en el proceso de análisis de la información. Una de las partes más costosas del proceso de reducción de dimensión no lineal es la búsqueda de \\(k\\)-vecinos cercanos, los algoritmos eficientes de búsqueda de vecinos son fundamentales para obtener en tiempos prácticos información de valor. Así mismo, asegurar la calidad de los vecinos es importante para confiar en las proyecciones que se obtienen."
  },
  {
    "objectID": "05-metric-IR.html#marco-teórico",
    "href": "05-metric-IR.html#marco-teórico",
    "title": "Búsqueda en espacios métricos",
    "section": "Marco teórico",
    "text": "Marco teórico\nUna de las formalizaciones más flexibles de búsqueda por similitud consiste en representar el problema en términos de espacios métricos. Un espacio métrico \\((U,d)\\) esta compuesto de un universo de objetos validos \\(U\\) y una función de distancia \\(d: U \\times U \\rightarrow \\Re^+\\). Para ser precisos, \\(d\\) es una métrica por lo que para todo \\(u,v,w \\in U\\) cumple las siguientes propiedades:\n\n\\(d(u, v) \\geq 0\\) y \\(d(u,v)= 0 \\iff u \\equiv v\\) (positividad y equivalencia)\n\\(d(u, v) = d(v, u)\\) (simetría), y finalmente,\n\\(d(u, v) + d(v, w)  \\leq d(u, w) \\leq d(u, v) + d(v, w)\\) (desigualdad triangular).\n\nEl problema principal de la búsqueda en espacios métricos consiste en, dado el conjunto finito \\(S \\subseteq U\\), deseamos seleccionar elemento parecidos en \\(S\\) a una consulta \\(q \\in U\\) bajo una definición consistente de similitud.\n\n\\(k\\) vecinos cercanos\nDado un universo de objetos validos \\(U\\) y una función de distancia \\(d\\), y sea \\(S\\) un subconjunto finito de \\(U\\) y dadas la consulta \\(q \\in U\\) y el número entero positivo \\(k\\), el objetivo es encontrar \\(R\\) de tamaño \\(k\\) que minimiza \\(\\sum_{u \\in R} d(u, q)\\), para \\(R \\in 2^S\\). Se suele denotar como \\(k\\text{nn}(S, q)\\).\nExiste una solución trivial para el problema, que consiste en evaluar \\(d(q, u)\\) para todo \\(u \\in S\\). Sin embargo, en el caso de interés, i.e., el tamaño de la colección de datos, \\(n=|S|\\), es muy grande y la evaluación exhaustiva de \\(S\\) no escala. El problema se complica si adicionalmente la función \\(d\\) es costosa de evaluar computacionalmente, como suele suceder en datos complejos. La solución a este problema es indexar o pre-procesar \\(S\\), de tal forma que se evite evaluar la distancia contra la mayor cantidad de elementos de \\(S\\)."
  },
  {
    "objectID": "05-metric-IR.html#sobre-la-dimensión-intrínseca",
    "href": "05-metric-IR.html#sobre-la-dimensión-intrínseca",
    "title": "Búsqueda en espacios métricos",
    "section": "Sobre la dimensión intrínseca",
    "text": "Sobre la dimensión intrínseca\nEl modelo de espacios métricos proporciona simplicidad del marco de trabajo, ya que el universo \\(U\\) de objetos puede estar definido por vectores en cualquier dimensión, secuencias de símbolos, documentos escritos en lenguaje natural, gráficas, distribuciones de probabilidad, o incluso conjuntos de elementos, que a su vez, podrían ser colecciones de los objetos antes mencionados. Con la flexibilidad y potencia descrita viene implícita una debilidad, la inherente dependencia en la dimensionalidad intrínseca de los datos, que podemos entenderla de manera informal como la información necesaria que necesita contener o representar un elemento del espacio métrico para ser distinguido entre todos los objetos validos. Chavez et al. [@CNBYM2001] detallan una definición formal de la dimensionalidad intrínseca y de como es una generalización de la dimensión de un espacio vectorial. En términos prácticos, la dimensión intrínseca impacta principalmente de dos maneras, en primera instancia suele estar ligada con una función de distancia costosa, y segunda y más importante, destruye la capacidad de discriminación de los índices métricos tal que serán degradados a una evaluación exhaustiva. Lo anterior se debe al efecto que tiene la dimensión sobre la distribución de valores de distancia entre elementos de una colección. De manera más detallada, el aumento de la dimensión trae con sigo el incremento de la distancia mínima entre pares de elementos, y a su vez, la concentración alrededor de la media de las distancias entre objetos. Lo anterior se traduce como la incapacidad de usar la desigualdad del triángulo como filtro.\nDesde el punto de vista del tamaño del conjunto de datos \\(S\\), el problema es evidentemente lineal sin utilizar un índice, ya que basta con evaluar todos los elementos para obtener el resultado exacto. Recientemente se ha probado con diversos formalismos que si la dimensión intrínseca de los datos es suficientemente alta, entonces con cualquier índice posible, la complejidad de la búsqueda sigue siendo lineal en el caso exacto y aún en el caso aproximado. El problema puede reducirse a un problema NP-completo [@AFN2004], como detalla Hetland [@Hetland2020], quién reduce el problema de búsqueda al problema de minimum dominating set, un problema NP-completo clásico. Por otro lado, en 2018 Rubinstein probó que el problema de encontrar el par bicromático mas cercano tiene dureza cuadrática, lo cual implica que la búsqueda del vecino mas cercano tiene a su vez dureza lineal, aún en el sentido aproximado [@RUB2018]. Estos resultados, y otros semejantes en la literatura obligan a buscar soluciones de índices sublineales en el sentido probabilístico.\nPara abundar en lo anterior, la búsqueda de proximidad exacta requiere, por ejemplo, encontrar el vecino más cercano exacto; mientras que la búsqueda de proximidad aproximada da garantías de proximidad; lo que regresa estará a lo más \\(\\delta\\) veces más lejos que el verdadero vecino mas cercano. Los resultados descritos en el párrafo anterior establecen que no es posible crear un índice para cualquiera de estos dos casos. La única posibilidad de tener algoritmos verdaderamente sublineales es en el sentido probabilístico; es decir, la mayor parte de las veces darán el resultado correcto; pero cuando se equivocan el error cometido no está acotado."
  },
  {
    "objectID": "05-metric-IR.html#búsqueda-aproximada",
    "href": "05-metric-IR.html#búsqueda-aproximada",
    "title": "Búsqueda en espacios métricos",
    "section": "Búsqueda aproximada",
    "text": "Búsqueda aproximada\nCon la finalidad de cuantificar la calidad en el sentido probabilístico, es necesario definir una medida de calidad; en la literatura se puede encontrar que el recall es una medida bien aceptada, y esta definida como sigue: \\[recall(S, q, k) = \\frac{|k\\text{nn}(S, q) \\cap k\\text{nn}^*(S, q)|}{k}, \\]\ndonde \\(k\\)nn calcula los \\(k\\) vecinos de \\(q\\) en \\(S\\) de manera exacta y \\(k\\text{nn}^*\\) de manera aproximada, por lo que el valor de recall estará en el rango de 0 a 1, siendo 0 el peor y 1 el mejor.\nSe busca que un índice para búsqueda aproximada tenga un costo computacional bajo, i.e., rápido y bajo uso en memoria; y a la vez tenga alta calidad en su aproximación, i.e., recall cercano a 1. Claramente, los objetivos se contraponen y es necesario encontrar los métodos que mejor se ajusten a las necesidades del problema a solucionar.\n\nEsquemas de búsqueda de \\(k\\)-vecinos cercanos en gráficas\nEn [@GLS2008] se transforma el problema de búsqueda en espacios métricos al problema de navegación en una gráfica dónde los vértices representan al conjunto de datos y las aristas conexiones pesadas por un esquema especial de desorden con respecto a los vértices. Para resolver consultas se toma un vértice como inicio e iterativamente se reduce la distancia de los nodos visitados a la consulta. Este trabajo tiene un valor teórico importante, sin embargo, es poco útil en la práctica dados los costos computacionales envueltos en la construcción de la gráfica, sobre todo su memoria cuadrática. Chavez y Téllez [@CT2010] estudian una gráfica navegable inducida por la gráfica de todos los vecinos cercanos, tanto directos como reversos y describen como manejar las componentes dentro de la misma. Este algoritmo requiere la construcción de la gráfica de todos los \\(k\\) vecinos cercanos, por lo que su construcción es muy costosa. Un algoritmo alternativo con un uso más reducido de memoria y construcciones más eficientes es el {} (RCT) [@HN2014]. En lugar de la construcción genérica de una gráfica, se crea un árbol, con un nodo raíz que siempre será usado para iniciar la búsqueda. Los nodos descendientes se obtienen por rango, i.e., orden al padre, y es la única información que se usa para la navegación. El grado de cada nodo es un parámetro que limita los requerimientos de memoria y el costo de las búsquedas, en intercambio con la calidad de los resultados.\nEn Malkov et al. [@MPLK2014] se introduce el índice Navigable Small World (NSW), un esquema novedoso con un desempeño notable. Dichos autores sugieren que la velocidad de búsqueda y precisión de NSW se debe a que su algoritmo de construcción captura las propiedades de Mundo Pequeño (Small World) de una base de datos métrica. Los requerimientos computacionales del NSW para su funcionamiento óptimo y el tiempo de construcción son altos, pero muy por debajo de esquemas anteriores. La construcción de NSW es incremental, se inserta un elemento a la vez, el algoritmo consiste en conectar el \\(j\\)-ésimo elemento con sus \\(k\\) vecinos cercanos aproximados tomados en los \\(j-1\\) elementos previamente indexados. Las conexiones son no-dirigidas, por lo que el grafo resultante también es no-dirigido. El orden de inserción debe ser aleatorizado para evitar varios casos con muy mal desempeño. Finalmente, el número de vecinos, \\(k\\), es un parámetro crucial que debe ser optimizado para cada base de datos. En [@MYD2018] se introduce una variante aún más veloz que consisten en una estructura jerárquica sobre la gráfica NSW; éste nuevo algoritmo reduce los peores casos y es capaz de reducir la memoria necesaria por la gráfica usando una selección más apropiada de las aristas que conectan los vértices. Ruiz et al. [@RCGT2015] introducen nuevos algoritmos para la navegación del NSW, los cuales son capaces de obtener resultados de mayor calidad a igualdad de memoria. Mas recientemente, Tellez et al. [@TRCG2021] presentan estrategias para calcular el grado de los vértices, y así mismo, de filtrado de los vértices que dan como resultado búsquedas más eficientes y gráficas más pequeñas. Dada la definición del NSW, la gráfica guarda información útil sobre la estructura de la colección de datos siendo representada, que hasta el momento ha sido poco explotada."
  },
  {
    "objectID": "05-metric-IR.html#bibliografía",
    "href": "05-metric-IR.html#bibliografía",
    "title": "Búsqueda en espacios métricos",
    "section": "Bibliografía",
    "text": "Bibliografía\n\n[@AFN2004] Alber, J., Fellows, M. R., & Niedermeier, R. (2004). Polynomial-time data reduction for dominating set. Journal of the ACM (JACM), 51(3), 363-384.\n[@AW2019] Amid, E., & Warmuth, M. K. (2019). TriMap: Large-scale dimensionality reduction using triplets. arXiv preprint arXiv:1910.00204.\n[@CNBYM2001] Chávez, E., Navarro, G., Baeza-Yates, R., & Marroquín, J. L. (2001). Searching in metric spaces. ACM computing surveys (CSUR), 33(3), 273-321.\n[@CT2010] Chávez, E., & Tellez, E. S. (2010, September). Navigating k-nearest neighbor graphs to solve nearest neighbor searches. In Mexican Conference on Pattern Recognition (pp. 270-280). Springer, Berlin, Heidelberg.\n[@DS2020] DS, D. (2020). A simple solution for the taxonomy enrichment task: Discovering hypernyms using nearest neighbor search.\n[@FH2017] Faessler, E., & Hahn, U. (2017, July). Semedico: a comprehensive semantic search engine for the life sciences. In Proceedings of ACL 2017, System Demonstrations (pp. 91-96).\n[@GCVR2018] Gallego, A. J., Calvo-Zaragoza, J., Valero-Mas, J. J., & Rico-Juan, J. R. (2018). Clustering-based k-nearest neighbor classification for large-scale data with neural codes representation. Pattern Recognition, 74, 531-543.\n[@GLS2008] Goyal, N., Lifshits, Y., & Schütze, H. (2008, February). Disorder inequality: a combinatorial approach to nearest neighbor search. In Proceedings of the 2008 international conference on web search and data mining (pp. 25-32).\n[@HN2014] Houle, M. E., & Nett, M. (2014). Rank-based similarity search: Reducing the dimensional dependence. IEEE transactions on pattern analysis and machine intelligence, 37(1), 136-150.\n[@Hetland2020] Hetland, M. L. (2020, September). Optimal Metric Search Is Equivalent to the Minimum Dominating Set Problem. In International Conference on Similarity Search and Applications (pp. 111-125). Springer, Cham.\n[@LV2017] Lee, J. A., & Verleysen, M. (2007). Nonlinear dimensionality reduction (Vol. 1). New York: Springer.\n[@MHM2018] McInnes, L., Healy, J., & Melville, J. (2018). Umap: Uniform manifold approximation and projection for dimension reduction. arXiv preprint arXiv:1802.03426.\n[@MPLK2014] Malkov, Y., Ponomarenko, A., Logvinov, A., & Krylov, V. (2014). Approximate nearest neighbor algorithm based on navigable small world graphs. Information Systems, 45, 61-68.\n[@MYD2018] Malkov, Y. A., & Yashunin, D. A. (2018). Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs. IEEE transactions on pattern analysis and machine intelligence, 42(4), 824-836.\n[@OTGMM2020] Ortiz-Bejar, J., Téllez, E. S., Graff, M., Moctezuma, D., & Miranda-Jiménez, S. (2020). Improving k Nearest Neighbors and Naïve Bayes Classifiers Through Space Transformations and Model Selection. IEEE Access, 8, 221669-221688.\n[@RCGT2015] Ruiz, G., Chávez, E., Graff, M., & Téllez, E. S. (2015, October). Finding near neighbors through local search. In International Conference on Similarity Search and Applications (pp. 103-109). Springer, Cham.\n[@RUB2018] Rubinstein, A. (2018, June). Hardness of approximate nearest neighbor search. In Proceedings of the 50th annual ACM SIGACT symposium on theory of computing (pp. 1260-1268).\n[@SKL2011] Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., … & Duchesnay, E. (2011). Scikit-learn: Machine learning in Python. the Journal of machine Learning research, 12, 2825-2830.\n[@SPA2019] Soto, A. J., Przybyła, P., & Ananiadou, S. (2019). Thalia: semantic search engine for biomedical abstracts. Bioinformatics, 35(10), 1799-1801.\n[@SS2021] Sharma, K. K., & Seal, A. (2021). Spectral embedded generalized mean based k-nearest neighbors clustering with S-distance. Expert Systems with Applications, 169, 114326.\n[@TR2022] Tellez, E. S., & Ruiz, G. (2022). Similarity search on neighbor’s graphs with automatic Pareto optimal performance and minimum expected quality setups based on hyperparameter optimization. arXiv preprint arXiv:2201.07917.\n[@TRCG2021] Tellez, E. S., Ruiz, G., Chavez, E., & Graff, M. (2021). A scalable solution to the nearest neighbor search problem through local-search methods on neighbor graphs. Pattern Analysis and Applications, 24(2), 763-777.\n[@VMH2018] Van der Maaten, L., & Hinton, G. (2008). Visualizing data using t-SNE. Journal of machine learning research, 9(11).\n[@WPAA2017] Wachsmuth, H., Potthast, M., Al Khatib, K., Ajjour, Y., Puschmann, J., Qu, J., … & Stein, B. (2017, September). Building an argument search engine for the web. In Proceedings of the 4th Workshop on Argument Mining (pp. 49-59).\n[@YCC2020] Yu, Q., Chen, K. H., & Chen, J. J. (2020, September). Using a set of triangle inequalities to accelerate k-means clustering. In International Conference on Similarity Search and Applications (pp. 297-311). Springer, Cham."
  },
  {
    "objectID": "05-metric-IR.html#ejemplo-de-uso-con-similaritysearch",
    "href": "05-metric-IR.html#ejemplo-de-uso-con-similaritysearch",
    "title": "Búsqueda en espacios métricos",
    "section": "Ejemplo de uso con SimilaritySearch",
    "text": "Ejemplo de uso con SimilaritySearch\n\nusing CSV, DataFrames\nusing SimilaritySearch, StatsBase\nusing PlotlyLight, JSON3, Cobweb\nusing LinearAlgebra, HDF5\nPlotlyLight.settings.use_iframe = true  # necesario para quarto / jupyter / etc.\n\ntrue\n\n\n\nDescargando los datos\nPara estos ejemplos, estaremos usando el segmento de Español de la base de datos Wikipedia Image-Text (WIT); previamente se calcularon los encajes de las imágenes y el texto usando el modelo Jina CLIP v2 https://huggingface.co/jinaai/jina-clip-v2.\n\npath = \"WIT-es_jina-clip-v2_sample\"\nif !isdir(path)\n  run(`git clone https://huggingface.co/datasets/sadit/WIT-es_jina-clip-v2_sample/`)\nend\n\nLa lectura de la base de datos vectorial se realizará con HDF5\n\nmetaimages = \"$path/es-wit-images.tsv\"\nvecimages = \"$path/es-wit-images.h5\"\n\nX = Matrix{Float16}(h5read(vecimages, \"emb\"))\n\n1024×318514 Matrix{Float16}:\n -0.9116    0.146    -1.663    -0.3271   …  -0.2583    1.117    -0.2664\n  4.496     1.082     0.6924    4.164        1.444     3.73      2.361\n  1.166    -0.9385   -3.037    -2.19         1.483    -0.4084   -2.309\n  3.973     3.578     2.094    -0.841        2.078     3.725     2.709\n  0.2686   -2.83     -2.121    -1.5205       1.729    -0.4478    1.403\n -1.938    -2.945    -1.264    -1.327    …  -0.4111   -2.363    -2.533\n -0.0851   -0.4343   -0.1952   -1.795        2.553    -1.731     1.567\n  2.07     -0.4365    1.217     0.4392      -0.0975    2.232    -2.094\n -3.01     -0.1432   -1.505     0.5024      -0.4185   -2.9      -0.472\n -3.955    -0.7725    1.451     1.369       -4.367    -1.54     -3.855\n  ⋮                                      ⋱                      \n -0.804     0.04886   0.306    -0.06165  …  -0.3684   -0.4897   -0.4978\n  0.2059    0.08386   0.4778   -0.374       -0.1692    0.3005    0.02394\n  0.06915  -0.164     0.3442   -0.1354       0.1407    0.10535   0.431\n -0.2593    0.1254    0.417    -0.4377       0.3865    0.2659    0.404\n -0.1729   -0.1938   -0.2198   -0.00975      0.4768   -0.06018   0.3657\n  0.0629   -0.1782    0.10474  -0.1715   …  -0.5806    0.1943   -0.3857\n  0.4314    0.2861    0.7065    0.5474       0.087     0.4092    0.1934\n -0.04266   0.0638    0.127     0.01243      0.07764  -0.03763  -0.04874\n  0.2544    0.3604   -0.04514   0.1028       0.701     0.2524    0.1526\n\n\nEn particular, se convirtió a números de punto flotante de precisión media; solo los procesadores más nuevos le sacan provecho a estas representaciones en SIMD, pero en cualquier caso nos sirve para mantener la base de datos en un tamaño razonable.\nAhora leemos los metadatos\n\nD = CSV.read(metaimages, DataFrame)\ndisplay(names(D))\nDict(pairs(D[1, :]))\n\n19-element Vector{String}:\n \"language\"\n \"page_url\"\n \"image_url\"\n \"page_title\"\n \"section_title\"\n \"hierarchical_section_title\"\n \"caption_reference_description\"\n \"caption_attribution_description\"\n \"caption_alt_text_description\"\n \"mime_type\"\n \"original_height\"\n \"original_width\"\n \"is_main_image\"\n \"attribution_passes_lang_id\"\n \"page_changed_recently\"\n \"context_page_description\"\n \"context_section_description\"\n \"ID\"\n \"image_url_sha256\"\n\n\nDict{Symbol, Any} with 19 entries:\n  :image_url_sha256                =&gt; \"14f55329b6d8f9e7125ae6288af2e82807285f11…\n  :ID                              =&gt; String15(\"00000_0000009\")\n  :caption_reference_description   =&gt; \"Torreón en el castillo de Barcience, en …\n  :context_section_description     =&gt; \"Hacia 1427 contrajo matrimonio con Leono…\n  :hierarchical_section_title      =&gt; \"Juan de Silva y Meneses / Biografía / Pr…\n  :page_url                        =&gt; \"https://es.wikipedia.org/wiki/Juan_de_Si…\n  :attribution_passes_lang_id      =&gt; false\n  :section_title                   =&gt; \"Primer matrimonio y ascenso en la Corte …\n  :is_main_image                   =&gt; false\n  :image_url                       =&gt; \"http://upload.wikimedia.org/wikipedia/co…\n  :page_title                      =&gt; \"Juan de Silva y Meneses\"\n  :original_width                  =&gt; 960\n  :page_changed_recently           =&gt; false\n  :caption_attribution_description =&gt; \"Castle of Barcience, near Maqueda, in th…\n  :context_page_description        =&gt; \"Juan de Silva y Meneses, noble y cortesa…\n  :original_height                 =&gt; 1280\n  :language                        =&gt; \"es\"\n  :mime_type                       =&gt; String15(\"image/jpeg\")\n  :caption_alt_text_description    =&gt; missing"
  },
  {
    "objectID": "05-metric-IR.html#búsqueda-por-fuerza-bruta-en-imágenes",
    "href": "05-metric-IR.html#búsqueda-por-fuerza-bruta-en-imágenes",
    "title": "Búsqueda en espacios métricos",
    "section": "Búsqueda por fuerza bruta en imágenes",
    "text": "Búsqueda por fuerza bruta en imágenes\nUsando subconjuntos pequeños de la base de datos leída (Embeddings de imágenes con Jina CLIP v2), vamos a realizar algunas búsquedas.\n\nn = 10^4\ndb, queries = MatrixDatabase(X[:, 1:n]), MatrixDatabase(X[:, n+1:n+100])\ndist = SqL2_asf32()\nS = ExhaustiveSearch(; db, dist)\nctx = GenericContext()\n\nGenericContext{KnnSorted}(0, true, InformativeLog(1.0, Base.RefValue{Float64}(0.0), Base.Threads.SpinLock(0)))\n\n\nAhora las búsquedas\n\nknns = searchbatch(S, ctx, queries, 10)\n\n10×100 Matrix{IdWeight}:\n IdWeight(0x00000550, 97.6724)  …  IdWeight(0x0000078e, 71.1038)\n IdWeight(0x00001497, 103.409)     IdWeight(0x00001c94, 95.7726)\n IdWeight(0x00001ad9, 115.389)     IdWeight(0x0000067e, 106.031)\n IdWeight(0x000002a7, 171.187)     IdWeight(0x000024f1, 109.175)\n IdWeight(0x00000a4a, 172.74)      IdWeight(0x00001997, 112.583)\n IdWeight(0x00001b0b, 180.287)  …  IdWeight(0x00001368, 133.041)\n IdWeight(0x000021ea, 239.926)     IdWeight(0x00001f9f, 135.978)\n IdWeight(0x00000280, 258.994)     IdWeight(0x00000abc, 138.976)\n IdWeight(0x000025ba, 260.493)     IdWeight(0x00000c6a, 140.593)\n IdWeight(0x00001f6e, 265.5)       IdWeight(0x00001df4, 141.146)\n\n\nPodemos observar a que corresponde una de las consultas realizadas\n\nqID = 100\nr = D[10_000 + qID, :]\ndisplay(Dict(pairs(r)))\nh.img(src=r.image_url, alt=r.page_title, width=160)\n\nDict{Symbol, Any} with 19 entries:\n  :image_url_sha256                =&gt; \"3ab0c3b127c7665e3aebe5679b2e3d379c346a9d…\n  :ID                              =&gt; String15(\"00000_0231606\")\n  :caption_reference_description   =&gt; missing\n  :context_section_description     =&gt; \"Saint-Péran  es una población y comuna f…\n  :hierarchical_section_title      =&gt; \"Saint-Péran\"\n  :page_url                        =&gt; \"https://es.wikipedia.org/wiki/Saint-P%C3…\n  :attribution_passes_lang_id      =&gt; false\n  :section_title                   =&gt; missing\n  :is_main_image                   =&gt; true\n  :image_url                       =&gt; \"https://upload.wikimedia.org/wikipedia/c…\n  :page_title                      =&gt; \"Saint-Péran\"\n  :original_width                  =&gt; 2043\n  :page_changed_recently           =&gt; false\n  :caption_attribution_description =&gt; \"Français&#160;: Église de Saint-Péran.Br…\n  :context_page_description        =&gt; \"Saint-Péran es una población y comuna fr…\n  :original_height                 =&gt; 3064\n  :language                        =&gt; \"es\"\n  :mime_type                       =&gt; String15(\"image/jpeg\")\n  :caption_alt_text_description    =&gt; missing\n\n\n\n\n\nAhora las respuestas\n\n\nchildren = []\nfor p in view(knns, :, qID)\n  r = D[p.id, [:image_url, :page_url, :page_title]]\n  push!(children,\n    h.div(style=\"display: inline-block; margin-left: 0.25cm;\",\n      h.img(src=r.image_url, alt=r.page_title, width=160), h.br(),\n      h.a(r.page_title, href=r.page_url)\n    )\n  )\nend\n\nres = h.div(children)\n\nSaint-Martin-le-BouillantSaint-Aubin-du-DésertPercy (Mancha)ÉtouvyTirso (santo)Saint-Étienne-l'AllierTaillepiedFrasnoyMeilhardsDammartin-les-Templiers\n\n\nA continuación se muestran el histograma de distancias del 10-ésimo vecino cercano.\n\np = plot()\n#p = plot(x = 1:20, y = cumsum(randn(20)), type=\"scatter\", mode=\"lines+markers\")  # Make plot\np.layout.title.text = \"knn distance histogram\"\np.histogram(x=convert.(Float32, view(knns, 10, :)))\n\n\n\n\n\nEjercicios\nExtrae una lista de imagenes relativas a un tema de tu elección y genera una colección ligada por similitud entre ellas."
  },
  {
    "objectID": "05-metric-IR.html#búsqueda-con-texto",
    "href": "05-metric-IR.html#búsqueda-con-texto",
    "title": "Búsqueda en espacios métricos",
    "section": "Búsqueda con Texto",
    "text": "Búsqueda con Texto\nAhora vamos a realizar las búsquedas en la modalidad de texto, usando nuevamente los embeddings de Jina CLIP v2.\n\nmetatext = \"$path/es-wit-text.tsv\"\nvectext = \"$path/es-wit-text.h5\"\n\nQ = Matrix{Float16}(h5read(vectext, \"emb\"))\nDQ = CSV.read(metatext, DataFrame)\nnames(DQ)\n\n19-element Vector{String}:\n \"language\"\n \"page_url\"\n \"image_url\"\n \"page_title\"\n \"section_title\"\n \"hierarchical_section_title\"\n \"caption_reference_description\"\n \"caption_attribution_description\"\n \"caption_alt_text_description\"\n \"mime_type\"\n \"original_height\"\n \"original_width\"\n \"is_main_image\"\n \"attribution_passes_lang_id\"\n \"page_changed_recently\"\n \"context_page_description\"\n \"context_section_description\"\n \"ID\"\n \"image_url_sha256\"\n\n\nIndexaremos un pequeño segmento\n\n\nn = 10^4\ndb, queries = MatrixDatabase(Q[:, 1:n]), MatrixDatabase(Q[:, n+1:n+100])\n\nS = ExhaustiveSearch(; db, dist)\nknns = searchbatch(S, ctx, queries, 10)\n\n10×100 Matrix{IdWeight}:\n IdWeight(0x000013fb, 176.251)  …  IdWeight(0x000014fa, 132.966)\n IdWeight(0x00001bab, 179.758)     IdWeight(0x00000d31, 154.491)\n IdWeight(0x00002280, 190.799)     IdWeight(0x000025b4, 167.495)\n IdWeight(0x00002663, 194.201)     IdWeight(0x00001d22, 175.824)\n IdWeight(0x000018bd, 196.033)     IdWeight(0x00000fe3, 175.925)\n IdWeight(0x000025a6, 199.787)  …  IdWeight(0x0000207d, 176.041)\n IdWeight(0x0000226f, 200.673)     IdWeight(0x000000d1, 177.714)\n IdWeight(0x000003fa, 201.174)     IdWeight(0x00000647, 184.847)\n IdWeight(0x00000915, 203.565)     IdWeight(0x000008b4, 186.362)\n IdWeight(0x00000e71, 205.645)     IdWeight(0x00002089, 187.546)\n\n\nAhora veremos una de las consultas\n\nqID = 100\nr = DQ[10_000 + qID, :]\ndisplay(Dict(pairs(r)))\nh.img(src=r.image_url, alt=r.page_title, width=160)\n\nDict{Symbol, Any} with 19 entries:\n  :image_url_sha256                =&gt; \"5466614e57c876674ad5347395651c1132f592b4…\n  :ID                              =&gt; String15(\"00000_0211707\")\n  :caption_reference_description   =&gt; \"Vista posterior de un Volkswagen Brasili…\n  :context_section_description     =&gt; \"En la mayoría de los mercados de América…\n  :hierarchical_section_title      =&gt; \"Volkswagen Brasilia / Primeros años\"\n  :page_url                        =&gt; \"https://es.wikipedia.org/wiki/Volkswagen…\n  :attribution_passes_lang_id      =&gt; false\n  :section_title                   =&gt; \"Primeros años\"\n  :is_main_image                   =&gt; false\n  :image_url                       =&gt; \"https://upload.wikimedia.org/wikipedia/c…\n  :page_title                      =&gt; \"Volkswagen Brasilia\"\n  :original_width                  =&gt; 328\n  :page_changed_recently           =&gt; false\n  :caption_attribution_description =&gt; \"Português: Volkswagen Brasília Português…\n  :context_page_description        =&gt; \"El Volkswagen Brasilia fue un automóvil …\n  :original_height                 =&gt; 245\n  :language                        =&gt; \"es\"\n  :mime_type                       =&gt; String15(\"image/jpeg\")\n  :caption_alt_text_description    =&gt; missing\n\n\n\n\n\ny los resultados asociados\n\nchildren = []\nfor p in view(knns, :, qID)\n  r = DQ[p.id, [:image_url, :page_url, :page_title]]\n  push!(children,\n    h.div(style=\"display: inline-block; margin-left: 0.25cm;\",\n      h.img(src=r.image_url, alt=r.page_title, width=160), h.br(),\n      h.a(r.page_title, href=r.page_url)\n    )\n  )\nend\n\nres = h.div(children)\n\nFord VersaillesVolkswagen Polo IIIMotor TipoIKA-Renault TorinoMercedes-Benz MB 100Fiat TempraVolkswagen TouranMatrículas automovilísticas de BrasilCitroën BXOpel Ascona\n\n\nObservemos el histograma de distancias\n\np = plot()\np.layout.title.text = \"knn distance histogram - text \"\np.histogram(x=convert.(Float32, view(knns, 10, :)))\n\n\n\n\nComparemos con el de imágenes que anteriormente calculamos.\n\nEjercicios\nAnáliza las posibilidades de un buscador basado en embeddings neurales vs un búscador de texto completo disperso (unidad anterior). ¿De qué serviría usar ambos?"
  },
  {
    "objectID": "05-metric-IR.html#búsqueda-multimodal",
    "href": "05-metric-IR.html#búsqueda-multimodal",
    "title": "Búsqueda en espacios métricos",
    "section": "Búsqueda Multimodal",
    "text": "Búsqueda Multimodal\nFinalizaremos con búsqueda multimodal, con más datos\n\ndb, queries = MatrixDatabase(X), MatrixDatabase(Q[:, 1:100])\n\nS = ExhaustiveSearch(; db, dist)\n@time eknns = searchbatch(S, ctx, queries, 10)\n\n  0.363403 seconds (103 allocations: 12.734 KiB)\n\n\n10×100 Matrix{IdWeight}:\n IdWeight(0x0001a81a, 605.293)  …  IdWeight(0x0001710f, 601.911)\n IdWeight(0x00034b40, 608.942)     IdWeight(0x0001f3f7, 603.531)\n IdWeight(0x00032712, 610.634)     IdWeight(0x00015bd3, 615.286)\n IdWeight(0x00035216, 611.12)      IdWeight(0x00003b56, 623.938)\n IdWeight(0x00044d5f, 611.12)      IdWeight(0x0001194a, 625.19)\n IdWeight(0x00031a0c, 612.145)  …  IdWeight(0x00023b04, 627.171)\n IdWeight(0x000491cd, 613.351)     IdWeight(0x0003cfd4, 630.306)\n IdWeight(0x00017876, 615.067)     IdWeight(0x0002b7b1, 631.28)\n IdWeight(0x000481ac, 615.698)     IdWeight(0x0000ef2d, 632.689)\n IdWeight(0x00031b44, 616.111)     IdWeight(0x0004aa5a, 633.096)\n\n\nEn este momento tenemos el conjunto de resultados eknns, el cual fue generado con una búsqueda exacta. Observa los tiempos.\nAhora veamos una de las consultas\n\nqID = 7\nr = DQ[qID, :]\ndisplay(Dict(pairs(r)))\n\nh.img(src=r.image_url, alt=r.page_title, width=160)\n\nDict{Symbol, Any} with 19 entries:\n  :image_url_sha256                =&gt; \"735517acb164c7e062814d36a22d6f90f6dddb3e…\n  :ID                              =&gt; String15(\"00000_0000116\")\n  :caption_reference_description   =&gt; missing\n  :context_section_description     =&gt; \"Tipo de Motor: Monocilíndrico, 4 Tiempos…\n  :hierarchical_section_title      =&gt; \"Suzuki GN 125 / Características\"\n  :page_url                        =&gt; \"https://es.wikipedia.org/wiki/Suzuki_GN_…\n  :attribution_passes_lang_id      =&gt; true\n  :section_title                   =&gt; \"Características\"\n  :is_main_image                   =&gt; false\n  :image_url                       =&gt; \"https://upload.wikimedia.org/wikipedia/c…\n  :page_title                      =&gt; \"Suzuki GN 125\"\n  :original_width                  =&gt; 1600\n  :page_changed_recently           =&gt; true\n  :caption_attribution_description =&gt; \"Español: Suzuki GN 125\"\n  :context_page_description        =&gt; \"La Suzuki GN 125 es una motocicleta mono…\n  :original_height                 =&gt; 1200\n  :language                        =&gt; \"es\"\n  :mime_type                       =&gt; String15(\"image/jpeg\")\n  :caption_alt_text_description    =&gt; missing\n\n\n\n\n\nY sus respectivas respuestas\n\n\nchildren = []\nfor p in view(eknns, :, qID)\n  r = D[p.id, [:image_url, :page_url, :page_title]]\n  push!(children,\n    h.div(style=\"display: inline-block; margin-left: 0.25cm;\",\n      h.img(src=r.image_url, alt=r.page_title, width=160), h.br(),\n      h.a(r.page_title, href=r.page_url)\n    )\n  )\nend\n\nres = h.div(children)\n\nKawasaki EliminatorSuzuki GS1100 (E, ES, G, GK, GL, L, S)Redes semánticas naturalesNorton Motorcycle CompanyMotor de dos cilindros en líneaKawasaki W650Byte (revista)Serie Honda CXGas natural comprimidoHonda Wave\n\n\nObservemos el histograma de distancias y compare con los histogramas pasados.\n\np = plot()\np.layout.title.text = \"knn distance histogram - multimodal \"\np.histogram(x=convert.(Float32, view(eknns, 10, :)))"
  },
  {
    "objectID": "05-metric-IR.html#búsqueda-con-índice",
    "href": "05-metric-IR.html#búsqueda-con-índice",
    "title": "Búsqueda en espacios métricos",
    "section": "Búsqueda con índice",
    "text": "Búsqueda con índice\nAhora veremos como hacerlo más eficiente\n\nG = SearchGraph(; db, dist)\ngctx = SearchGraphContext(\n  hyperparameters_callback=OptimizeParameters(MinRecall(0.99))\n)\n@time index!(G, gctx)\n\nLOG add_vertex! sp=1 ep=1 n=1 BeamSearch(bsize=4, Δ=1.0, maxvisits=1000000) 2025-10-23T15:43:29.118\nLOG n.size quantiles:[0.0, 0.0, 0.0, 0.0, 0.0]\nLOG add_vertex! sp=514 ep=770 n=513 BeamSearch(bsize=16, Δ=1.3735981, maxvisits=836) 2025-10-23T15:43:33.093\nLOG n.size quantiles:[1.0, 3.0, 4.0, 6.0, 9.0]\nLOG add_vertex! sp=71189 ep=71445 n=71188 BeamSearch(bsize=11, Δ=1.09, maxvisits=1234) 2025-10-23T15:43:34.093\nLOG n.size quantiles:[1.0, 4.0, 5.0, 7.0, 12.0]\nLOG add_vertex! sp=116421 ep=116677 n=116420 BeamSearch(bsize=16, Δ=1.24, maxvisits=2048) 2025-10-23T15:43:35.097\nLOG n.size quantiles:[1.0, 4.0, 5.0, 7.0, 12.0]\nLOG add_vertex! sp=160368 ep=160624 n=160367 BeamSearch(bsize=12, Δ=1.2, maxvisits=2148) 2025-10-23T15:43:36.097\nLOG n.size quantiles:[1.0, 4.0, 6.0, 7.0, 12.0]\nLOG add_vertex! sp=204829 ep=205085 n=204828 BeamSearch(bsize=12, Δ=1.155, maxvisits=1136) 2025-10-23T15:43:37.100\nLOG n.size quantiles:[1.0, 4.0, 5.0, 7.0, 12.0]\nLOG add_vertex! sp=255972 ep=256228 n=255971 BeamSearch(bsize=12, Δ=1.155, maxvisits=1136) 2025-10-23T15:43:38.104\nLOG n.size quantiles:[1.0, 4.0, 6.0, 7.0, 12.0]\nLOG add_vertex! sp=296064 ep=296320 n=296063 BeamSearch(bsize=13, Δ=1.21, maxvisits=1922) 2025-10-23T15:43:39.109\nLOG n.size quantiles:[1.0, 4.0, 5.0, 7.0, 13.0]\n 11.877309 seconds (10.63 M allocations: 636.877 MiB, 1.38% gc time, 55.23% compilation time)\n\n\nSearchGraph{SqL2_asf32, MatrixDatabase{Matrix{Float16}}, SimilaritySearch.AdjacencyLists.AdjacencyList{UInt32}, Vector{UInt32}}\n  dist: SqL2_asf32 SqL2_asf32()\n  db: MatrixDatabase{Matrix{Float16}}\n  adj: SimilaritySearch.AdjacencyLists.AdjacencyList{UInt32}\n  hints: Array{UInt32}((70,)) UInt32[0x0001efb4, 0x00007896, 0x000166b4, 0x0002fc3b, 0x0000dac4, 0x00006680, 0x000211cd, 0x00009fb6, 0x0000d212, 0x000146d6  …  0x0003c0bc, 0x000051ac, 0x0000f8f5, 0x0000ebd7, 0x0001f13d, 0x000120aa, 0x0000fea9, 0x00028220, 0x0002c89d, 0x00007d0c]\n  algo: Base.RefValue{BeamSearch}\n  len: Base.RefValue{Int64}\n\n\nOptimizamos para cierta calidad\n\n@time optimize_index!(G, gctx, MinRecall(0.9); ksearch=10, queries=rand(queries, 32))\n\n\n┌ Warning: OPT low recal&gt; recall: 0.05, #objects: 318514, #queries: 32\n└ @ SimilaritySearch ~/.julia/packages/SimilaritySearch/G1Cjs/src/opt.jl:67\ncov = [680.9583740234375, 751.2710571289062, 772.7908935546875, 655.8380126953125, 778.883544921875, 704.1089477539062, 707.7154541015625, 701.170166015625, 748.06005859375, 687.599853515625, 687.599853515625, 681.12744140625, 678.14794921875, 845.689208984375, 736.181640625, 751.2710571289062, 745.7560424804688, 726.5538330078125, 829.2791748046875, 703.62255859375, 724.7279052734375, 634.7830200195312, 717.00341796875, 667.642333984375, 653.3759155273438, 678.14794921875, 754.8448486328125, 810.9833984375, 734.847900390625, 791.37548828125, 612.8863525390625, 710.4384765625]\n┌ Warning: OPT low recal&gt; recall: 0.05, #objects: 318514, #queries: 32\n└ @ SimilaritySearch ~/.julia/packages/SimilaritySearch/G1Cjs/src/opt.jl:67\ncov = [680.9583740234375, 751.2710571289062, 772.7908935546875, 655.8380126953125, 778.883544921875, 704.1089477539062, 707.7154541015625, 701.170166015625, 748.06005859375, 687.599853515625, 687.599853515625, 681.12744140625, 678.14794921875, 845.689208984375, 736.181640625, 751.2710571289062, 745.7560424804688, 726.5538330078125, 829.2791748046875, 703.62255859375, 724.7279052734375, 634.7830200195312, 717.00341796875, 667.642333984375, 653.3759155273438, 678.14794921875, 754.8448486328125, 810.9833984375, 734.847900390625, 791.37548828125, 612.8863525390625, 710.4384765625]\n┌ Warning: OPT low recal&gt; recall: 0.12187500000000002, #objects: 318514, #queries: 32\n└ @ SimilaritySearch ~/.julia/packages/SimilaritySearch/G1Cjs/src/opt.jl:67\ncov = [658.09033203125, 721.2841796875, 722.373291015625, 636.2335205078125, 721.59521484375, 698.8558959960938, 684.9322509765625, 687.0257568359375, 702.749267578125, 688.0485229492188, 688.0485229492188, 679.7513427734375, 652.6015625, 722.3235473632812, 680.2178344726562, 721.2841796875, 698.9967041015625, 681.0943603515625, 701.628173828125, 704.0721435546875, 710.3634033203125, 657.5235595703125, 655.99462890625, 655.1314697265625, 669.9657592773438, 652.6015625, 715.156982421875, 754.354736328125, 714.3896484375, 655.5367431640625, 600.0947265625, 671.34619140625]\n┌ Warning: OPT low recal&gt; recall: 0.15625, #objects: 318514, #queries: 32\n└ @ SimilaritySearch ~/.julia/packages/SimilaritySearch/G1Cjs/src/opt.jl:67\ncov = [650.8567504882812, 688.1087646484375, 759.794677734375, 617.6065673828125, 719.7030639648438, 687.997314453125, 688.156005859375, 683.3162231445312, 683.7244873046875, 687.599853515625, 687.599853515625, 673.4305419921875, 653.12451171875, 722.69677734375, 673.6943969726562, 688.1087646484375, 680.089111328125, 685.165771484375, 716.530029296875, 690.6617431640625, 702.7591552734375, 628.0341796875, 634.9300537109375, 632.1361083984375, 648.7008666992188, 653.12451171875, 710.96240234375, 769.3220825195312, 714.3896484375, 662.8131103515625, 604.1209716796875, 683.76513671875]\n┌ Warning: OPT low recal&gt; recall: 0.259375, #objects: 318514, #queries: 32\n└ @ SimilaritySearch ~/.julia/packages/SimilaritySearch/G1Cjs/src/opt.jl:67\ncov = [650.8567504882812, 696.17138671875, 745.77587890625, 615.6129150390625, 714.8070068359375, 656.6239013671875, 675.5859375, 650.2857055664062, 690.9210815429688, 671.9686889648438, 671.9686889648438, 675.0487060546875, 645.756591796875, 703.33203125, 670.3602294921875, 696.17138671875, 677.3406982421875, 667.9902954101562, 714.51123046875, 683.5093383789062, 688.510498046875, 626.64697265625, 634.9300537109375, 625.6976318359375, 640.2392578125, 645.756591796875, 698.7984619140625, 751.783935546875, 697.04833984375, 651.0771484375, 595.638427734375, 661.6921997070312]\n┌ Warning: OPT low recal&gt; recall: 0.05, #objects: 318514, #queries: 32\n└ @ SimilaritySearch ~/.julia/packages/SimilaritySearch/G1Cjs/src/opt.jl:67\ncov = [680.9583740234375, 751.2710571289062, 772.7908935546875, 655.8380126953125, 778.883544921875, 704.1089477539062, 707.7154541015625, 701.170166015625, 748.06005859375, 687.599853515625, 687.599853515625, 681.12744140625, 678.14794921875, 845.689208984375, 736.181640625, 751.2710571289062, 745.7560424804688, 726.5538330078125, 829.2791748046875, 703.62255859375, 724.7279052734375, 634.7830200195312, 717.00341796875, 667.642333984375, 653.3759155273438, 678.14794921875, 754.8448486328125, 810.9833984375, 734.847900390625, 791.37548828125, 620.0990600585938, 710.4384765625]\n┌ Warning: OPT low recal&gt; recall: 0.024999999999999998, #objects: 318514, #queries: 32\n└ @ SimilaritySearch ~/.julia/packages/SimilaritySearch/G1Cjs/src/opt.jl:67\ncov = [691.65576171875, 818.3192138671875, 782.093017578125, 686.3458251953125, 802.71435546875, 704.1089477539062, 787.41943359375, 763.177978515625, 750.3307495117188, 711.1734619140625, 711.1734619140625, 791.050537109375, 679.2081909179688, 845.689208984375, 739.9598388671875, 818.3192138671875, 764.5305786132812, 726.5538330078125, 829.2791748046875, 705.463623046875, 733.5308837890625, 646.4071044921875, 723.8204956054688, 687.932373046875, 839.7944946289062, 679.2081909179688, 783.609375, 835.8453369140625, 827.0445556640625, 791.37548828125, 640.4025268554688, 716.44482421875]\n┌ Warning: OPT low recal&gt; recall: 0.04062500000000001, #objects: 318514, #queries: 32\n└ @ SimilaritySearch ~/.julia/packages/SimilaritySearch/G1Cjs/src/opt.jl:67\ncov = [670.2130126953125, 748.2506103515625, 771.16357421875, 661.0783081054688, 728.2699584960938, 696.1090698242188, 701.5476684570312, 701.170166015625, 741.7130126953125, 710.5018310546875, 710.5018310546875, 681.12744140625, 668.07666015625, 795.252685546875, 708.9701538085938, 748.2506103515625, 730.8685302734375, 708.579345703125, 737.0537109375, 698.9497680664062, 756.6915283203125, 657.5235595703125, 717.00341796875, 673.9359741210938, 669.9657592773438, 668.07666015625, 741.895751953125, 810.06005859375, 748.5692138671875, 791.37548828125, 604.1209716796875, 710.4384765625]\n┌ Warning: OPT low recal&gt; recall: 0.031249999999999997, #objects: 318514, #queries: 32\n└ @ SimilaritySearch ~/.julia/packages/SimilaritySearch/G1Cjs/src/opt.jl:67\ncov = [680.9583740234375, 751.2710571289062, 782.093017578125, 661.0783081054688, 778.883544921875, 704.1089477539062, 707.7154541015625, 701.170166015625, 748.06005859375, 710.5018310546875, 710.5018310546875, 681.12744140625, 679.2081909179688, 845.689208984375, 736.181640625, 751.2710571289062, 745.7560424804688, 726.5538330078125, 829.2791748046875, 703.62255859375, 724.7279052734375, 648.320068359375, 717.00341796875, 673.9359741210938, 669.9657592773438, 679.2081909179688, 754.8448486328125, 810.9833984375, 734.847900390625, 791.37548828125, 622.4653930664062, 710.4384765625]\n┌ Warning: OPT low recal&gt; recall: 0.09062500000000001, #objects: 318514, #queries: 32\n└ @ SimilaritySearch ~/.julia/packages/SimilaritySearch/G1Cjs/src/opt.jl:67\ncov = [670.2130126953125, 720.51171875, 764.08984375, 641.0982666015625, 728.2699584960938, 695.2686767578125, 695.8130493164062, 698.819580078125, 731.007568359375, 687.599853515625, 687.599853515625, 679.7513427734375, 665.2176513671875, 789.6669921875, 708.9701538085938, 720.51171875, 729.8187255859375, 698.4781494140625, 731.8641967773438, 696.5958251953125, 714.5098266601562, 634.7830200195312, 635.896240234375, 656.1807250976562, 650.8583984375, 665.2176513671875, 740.9832153320312, 808.4053955078125, 728.1640625, 791.37548828125, 604.1209716796875, 696.1136474609375]\n┌ Warning: OPT low recal&gt; recall: 0.19062500000000004, #objects: 318514, #queries: 32\n└ @ SimilaritySearch ~/.julia/packages/SimilaritySearch/G1Cjs/src/opt.jl:67\ncov = [658.09033203125, 716.480712890625, 746.913818359375, 615.6129150390625, 718.0546875, 656.6239013671875, 686.6375122070312, 687.0257568359375, 702.749267578125, 681.518798828125, 681.518798828125, 679.7513427734375, 649.0391235351562, 704.4138793945312, 673.5721435546875, 716.480712890625, 686.4442749023438, 681.0512084960938, 716.530029296875, 684.8226318359375, 692.14111328125, 626.64697265625, 634.9300537109375, 626.4940185546875, 640.2392578125, 649.0391235351562, 710.9561157226562, 758.398193359375, 723.772705078125, 651.0771484375, 599.6121826171875, 678.866455078125]\n┌ Warning: OPT low recal&gt; recall: 0.19687500000000005, #objects: 318514, #queries: 32\n└ @ SimilaritySearch ~/.julia/packages/SimilaritySearch/G1Cjs/src/opt.jl:67\ncov = [658.09033203125, 716.480712890625, 746.913818359375, 615.6129150390625, 718.0546875, 656.6239013671875, 686.6375122070312, 687.0257568359375, 702.749267578125, 681.518798828125, 681.518798828125, 679.7513427734375, 649.0391235351562, 703.33203125, 673.5721435546875, 716.480712890625, 682.5189208984375, 681.0512084960938, 714.55029296875, 683.5093383789062, 692.14111328125, 626.64697265625, 634.9300537109375, 626.4940185546875, 640.2392578125, 649.0391235351562, 710.9561157226562, 754.8391723632812, 699.982666015625, 651.0771484375, 599.6121826171875, 678.866455078125]\n  1.196519 seconds (990.25 k allocations: 72.876 MiB, 74.07% compilation time)\n\n\n\n\n16-element Vector{Pair}:\n BeamSearch(bsize=10, Δ=1.2502351, maxvisits=1000000) =&gt; (visited = (min = 3003, mean = 3848.375, max = 3915), radius = (min = 592.311279296875, mean = 650.463544845581, max = 720.5722045898438), recall = 0.7250000000000001, searchtime = 0.00013269446875, conf = BeamSearch(bsize=10, Δ=1.2502351, maxvisits=1000000))\n BeamSearch(bsize=10, Δ=1.3783842, maxvisits=1000000) =&gt; (visited = (min = 3316, mean = 3896.28125, max = 3915), radius = (min = 592.311279296875, mean = 650.463544845581, max = 720.5722045898438), recall = 0.7250000000000001, searchtime = 0.00013420584375, conf = BeamSearch(bsize=10, Δ=1.3783842, maxvisits=1000000))\n    BeamSearch(bsize=10, Δ=1.1907, maxvisits=1000000) =&gt; (visited = (min = 1439, mean = 3759.625, max = 3915), radius = (min = 592.311279296875, mean = 650.463544845581, max = 720.5722045898438), recall = 0.7250000000000001, searchtime = 0.0001278069375, conf = BeamSearch(bsize=10, Δ=1.1907, maxvisits=1000000))\n BeamSearch(bsize=10, Δ=1.3127469, maxvisits=1000000) =&gt; (visited = (min = 3316, mean = 3896.28125, max = 3915), radius = (min = 592.311279296875, mean = 650.463544845581, max = 720.5722045898438), recall = 0.7250000000000001, searchtime = 0.00013381746875, conf = BeamSearch(bsize=10, Δ=1.3127469, maxvisits=1000000))\n      BeamSearch(bsize=10, Δ=1.28, maxvisits=1000000) =&gt; (visited = (min = 3316, mean = 3892.40625, max = 3915), radius = (min = 592.311279296875, mean = 650.463544845581, max = 720.5722045898438), recall = 0.7250000000000001, searchtime = 0.0001336905625, conf = BeamSearch(bsize=10, Δ=1.28, maxvisits=1000000))\n      BeamSearch(bsize=10, Δ=1.22, maxvisits=1000000) =&gt; (visited = (min = 2682, mean = 3834.8125, max = 3915), radius = (min = 592.311279296875, mean = 650.463544845581, max = 720.5722045898438), recall = 0.7250000000000001, searchtime = 0.00013226340625, conf = BeamSearch(bsize=10, Δ=1.22, maxvisits=1000000))\n      BeamSearch(bsize=10, Δ=1.25, maxvisits=1000000) =&gt; (visited = (min = 3003, mean = 3848.375, max = 3915), radius = (min = 592.311279296875, mean = 650.463544845581, max = 720.5722045898438), recall = 0.7250000000000001, searchtime = 0.00013279184375, conf = BeamSearch(bsize=10, Δ=1.25, maxvisits=1000000))\n      BeamSearch(bsize=10, Δ=1.35, maxvisits=1000000) =&gt; (visited = (min = 3316, mean = 3896.28125, max = 3915), radius = (min = 592.311279296875, mean = 650.463544845581, max = 720.5722045898438), recall = 0.7250000000000001, searchtime = 0.00013405634375, conf = BeamSearch(bsize=10, Δ=1.35, maxvisits=1000000))\n BeamSearch(bsize=14, Δ=1.2762815, maxvisits=1000000) =&gt; (visited = (min = 3915, mean = 3915.0, max = 3915), radius = (min = 593.807861328125, mean = 651.4073505401611, max = 720.5722045898438), recall = 0.7187499999999998, searchtime = 0.000137586625, conf = BeamSearch(bsize=14, Δ=1.2762815, maxvisits=1000000))\n BeamSearch(bsize=14, Δ=1.2155062, maxvisits=1000000) =&gt; (visited = (min = 1720, mean = 3846.40625, max = 3915), radius = (min = 593.807861328125, mean = 651.4073505401611, max = 720.5722045898438), recall = 0.7187499999999998, searchtime = 0.00013682059375, conf = BeamSearch(bsize=14, Δ=1.2155062, maxvisits=1000000))\n      BeamSearch(bsize=14, Δ=1.19, maxvisits=1000000) =&gt; (visited = (min = 1437, mean = 3837.5625, max = 3915), radius = (min = 593.807861328125, mean = 651.4073505401611, max = 720.5722045898438), recall = 0.7187499999999998, searchtime = 0.000135276875, conf = BeamSearch(bsize=14, Δ=1.19, maxvisits=1000000))\n BeamSearch(bsize=14, Δ=1.3400955, maxvisits=1000000) =&gt; (visited = (min = 3915, mean = 3915.0, max = 3915), radius = (min = 593.807861328125, mean = 651.4073505401611, max = 720.5722045898438), recall = 0.7187499999999998, searchtime = 0.00013910853125, conf = BeamSearch(bsize=14, Δ=1.3400955, maxvisits=1000000))\n      BeamSearch(bsize=14, Δ=1.25, maxvisits=1000000) =&gt; (visited = (min = 3061, mean = 3888.3125, max = 3915), radius = (min = 593.807861328125, mean = 651.4073505401611, max = 720.5722045898438), recall = 0.7187499999999998, searchtime = 0.00013733271875, conf = BeamSearch(bsize=14, Δ=1.25, maxvisits=1000000))\n  BeamSearch(bsize=8, Δ=1.2155062, maxvisits=1000000) =&gt; (visited = (min = 1561, mean = 3823.15625, max = 3915), radius = (min = 595.2412719726562, mean = 650.9367542266846, max = 720.5722045898438), recall = 0.7125000000000001, searchtime = 0.00013424628125, conf = BeamSearch(bsize=8, Δ=1.2155062, maxvisits=1000000))\n  BeamSearch(bsize=8, Δ=1.2762815, maxvisits=1000000) =&gt; (visited = (min = 3915, mean = 3915.0, max = 3915), radius = (min = 595.2412719726562, mean = 650.9367542266846, max = 720.5722045898438), recall = 0.7125000000000001, searchtime = 0.0001355425625, conf = BeamSearch(bsize=8, Δ=1.2762815, maxvisits=1000000))\n  BeamSearch(bsize=14, Δ=1.157625, maxvisits=1000000) =&gt; (visited = (min = 1021, mean = 3460.65625, max = 3915), radius = (min = 593.807861328125, mean = 651.4301204681396, max = 720.5722045898438), recall = 0.7124999999999998, searchtime = 0.00012638925, conf = BeamSearch(bsize=14, Δ=1.157625, maxvisits=1000000))\n\n\nVamos a buscar en el índice\n\n@time gknns = searchbatch(G, gctx, queries, 10)\n\n  0.491324 seconds (426.38 k allocations: 27.303 MiB, 95.08% compilation time)\n\n\n10×100 Matrix{IdWeight}:\n IdWeight(0x0001a81a, 605.293)  …  IdWeight(0x0001710f, 601.911)\n IdWeight(0x00034b40, 608.942)     IdWeight(0x0001f3f7, 603.531)\n IdWeight(0x00044d5f, 611.12)      IdWeight(0x00015bd3, 615.286)\n IdWeight(0x00035216, 611.12)      IdWeight(0x00003b56, 623.938)\n IdWeight(0x000491cd, 613.351)     IdWeight(0x0001194a, 625.19)\n IdWeight(0x000481ac, 615.698)  …  IdWeight(0x00023b04, 627.171)\n IdWeight(0x00011ac0, 619.328)     IdWeight(0x0003cfd4, 630.306)\n IdWeight(0x000497b9, 620.583)     IdWeight(0x0000ef2d, 632.689)\n IdWeight(0x00030c86, 620.585)     IdWeight(0x0000fc1a, 633.244)\n IdWeight(0x0001f3f7, 622.104)     IdWeight(0x00014093, 633.248)\n\n\nVamos observar algunas de las consultas\n\nr = DQ[qID, :]\ndisplay(Dict(pairs(r)))\nh.img(src=r.image_url, alt=r.page_title, width=160)\n\nDict{Symbol, Any} with 19 entries:\n  :image_url_sha256                =&gt; \"735517acb164c7e062814d36a22d6f90f6dddb3e…\n  :ID                              =&gt; String15(\"00000_0000116\")\n  :caption_reference_description   =&gt; missing\n  :context_section_description     =&gt; \"Tipo de Motor: Monocilíndrico, 4 Tiempos…\n  :hierarchical_section_title      =&gt; \"Suzuki GN 125 / Características\"\n  :page_url                        =&gt; \"https://es.wikipedia.org/wiki/Suzuki_GN_…\n  :attribution_passes_lang_id      =&gt; true\n  :section_title                   =&gt; \"Características\"\n  :is_main_image                   =&gt; false\n  :image_url                       =&gt; \"https://upload.wikimedia.org/wikipedia/c…\n  :page_title                      =&gt; \"Suzuki GN 125\"\n  :original_width                  =&gt; 1600\n  :page_changed_recently           =&gt; true\n  :caption_attribution_description =&gt; \"Español: Suzuki GN 125\"\n  :context_page_description        =&gt; \"La Suzuki GN 125 es una motocicleta mono…\n  :original_height                 =&gt; 1200\n  :language                        =&gt; \"es\"\n  :mime_type                       =&gt; String15(\"image/jpeg\")\n  :caption_alt_text_description    =&gt; missing\n\n\n\n\n\nY sus resultados\n\n\nchildren = []\nfor p in view(gknns, :, qID)\n  r = D[p.id, [:image_url, :page_url, :page_title]]\n  push!(children,\n    h.div(style=\"display: inline-block; margin-left: 0.25cm;\",\n      h.img(src=r.image_url, alt=r.page_title, width=160), h.br(),\n      h.a(r.page_title, href=r.page_url)\n    )\n  )\nend\n\nres = h.div(children)\n\nKawasaki EliminatorSuzuki GS1100 (E, ES, G, GK, GL, L, S)Redes semánticas naturalesNorton Motorcycle CompanyMotor de dos cilindros en líneaKawasaki W650Byte (revista)Serie Honda CXGas natural comprimidoHonda Wave\n\n\nSus histogramas\n\np = plot()\np.layout.title.text = \"knn distance histogram - indexed - multimodal \"\np.histogram(x=convert.(Float32, view(gknns, 10, :)))\n\n\n\n\nAhora medimos el recall\n\nmacrorecall(eknns, gknns)\n\n0.8659999999999997\n\n\nVemos que no es tan bueno, pero es básicamente porque intercambiamos velocidad por calidad. A continuación veremos como mejorar un poco la calidad, manipulando algunos de los parametros de búsqueda.\n\nB_ = B = G.algo[]\nfor in in 1:5\n  G.algo[] = B = BeamSearch(B.bsize, B.Δ, 3 * B.maxvisits)\n  @time \"searching $B\" gknns = searchbatch(G, gctx, queries, 10)\n  @info macrorecall(eknns, gknns)\nend\nG.algo[] = B_\n\n\nsearching BeamSearch(bsize=10, Δ=1.2502351, maxvisits=23490): 0.069224 seconds (403 allocations: 19.094 KiB)\n[ Info: 0.9170000000000001\nsearching BeamSearch(bsize=10, Δ=1.2502351, maxvisits=70470): 0.093709 seconds (402 allocations: 19.078 KiB)\n[ Info: 0.9250000000000004\nsearching BeamSearch(bsize=10, Δ=1.2502351, maxvisits=211410): 0.093501 seconds (402 allocations: 19.078 KiB)\n[ Info: 0.9250000000000004\nsearching BeamSearch(bsize=10, Δ=1.2502351, maxvisits=634230): 0.094189 seconds (402 allocations: 19.078 KiB)\n[ Info: 0.9250000000000004\nsearching BeamSearch(bsize=10, Δ=1.2502351, maxvisits=1902690): 0.085977 seconds (402 allocations: 19.078 KiB)\n[ Info: 0.9250000000000004\n\n\n\n\nBeamSearch(bsize=10, Δ=1.2502351, maxvisits=7830)\n\n\n\nEjercicios\nGenerá un minibuscador de imágenes a través de texto; escoge algunas consultas para ver que recall es adecuado visualmente sin afectar la percepción.\nEjemplo de resultado https://colab.research.google.com/drive/1E_XLhKBD371B7DXnJELUca5N2pEJPjA0?usp=sharing. Para este ejemplo se debe tener cuidado de iniciar la instancia de Colab con GPUs; y se debe correr el servicio que esta empotrado en una de sus celdas."
  },
  {
    "objectID": "01-basico.html",
    "href": "01-basico.html",
    "title": "",
    "section": "",
    "text": "Código"
  },
  {
    "objectID": "01-basico.html#sec-julia",
    "href": "01-basico.html#sec-julia",
    "title": "",
    "section": "El lenguaje de programación Julia",
    "text": "El lenguaje de programación Julia\nEl código se suele organizar en scripts, módulos y paquetes. Cada uno de estos define tipos y funciones que interactuan para componer las soluciones deseadas.\nEl resto de esta unidad esta dedicada a precisar la sintaxis del lenguaje y anotaciones de importancia sobre su funcionamiento."
  },
  {
    "objectID": "01-basico.html#instalación",
    "href": "01-basico.html#instalación",
    "title": "",
    "section": "Instalación",
    "text": "Instalación\nEl sitio oficial recomienda el uso de juliaup, una herramienta que permite manejar diferentes versiones de Julia y mantenerlas actualizarlas.\nhttps://julialang.org/install/\nLas versiones de Julia siguen el paradigma de semantic versioning (semver), por lo que juliaup permite gestionarlas de manera simple y efectiva. La versión estable es la 1.10 y las más nuevas son la 1.11 y la 1.12.\nTambién es posible usar Colab de Google con el kernel para Julia; este usar julia 1.11 y hasta el momento, es el único disponible."
  },
  {
    "objectID": "01-basico.html#manos-a-la-obra",
    "href": "01-basico.html#manos-a-la-obra",
    "title": "",
    "section": "Manos a la obra",
    "text": "Manos a la obra\nUna vez instalado, se puede ejecutar un REPL de Julia en la terminal ejecutando\n```{bash}\n$ julia\n```\ndado que instalamos con juliaup podemos mantener diferentes versiones, e.g.,\n```{bash}\n$ juliaup list\n```\nque nos mostrará una larga lista de posibles channels o versiones de instalación\n```{bash}\n\n$ juliaup add 1.10\n$ juliaup default 1.10\n```\nestas instrucciones añadirán la versión 1.10 y la establecerá como versión o canal por omisión. Puedes llamar diferentes versiones ejecutando julia +channel como sigue:\n```{bash}\n$ julia +1.12\n\n               _\n   _       _ _(_)_     |  Documentation: https://docs.julialang.org\n  (_)     | (_) (_)    |\n   _ _   _| |_  __ _   |  Type \"?\" for help, \"]?\" for Pkg help.\n  | | | | | | |/ _` |  |\n  | | |_| | | | (_| |  |  Version 1.12.1 (2025-10-17)\n _/ |\\__'_|_|_|\\__'_|  |  Official https://julialang.org release\n|__/                   |\n\njulia&gt;\n\n```\n\nCreando el famoso “Hola mundo”\nUno de los programas más comunes es el siguiente\n\nprintln(\"¡Hola 🌎!\")\n\n¡Hola 🌎!\n\n\n\n\nColab\nEs posible usar Colab para reducir la complejidad de la instalación, ya que cuenta con un kernel de Julia. Como se mencionaba anteriormente, solo se soporta la versión 1.11 que es subóptima con las versiones de paquetes que usaremos más adelante. Adicionalmente, se tiene limitante de los recursos limitados que se nos proporcionen, en particular al momento de escribir estas notas, aunque los recursos que se otorgan suelen ser suficientes para pruebas, no lo son en otros ámbitos: solo se tienen 2 vcpus y tiempos de ejecución limitados.\n\n\nJupyter\nUna vez instalado julia; debemos instalar el paquete IJulia que instalará todo lo necesario para correr Jupyter (ver la sección de Pkg al final de esta unidad para más información sobre paquetes). Una vez corriendo, se debe seleccionar crear un notebook específicando el kernel de Julia para utilizarlo.\n\n\nEjercicios\nSegún sus posibilidades de equipo:\n\nInstale Julia 1.10, luego instale el paquete IJulia y ejecute Jupyter.\nCree un notebook con Colab con el kernel de Julia."
  },
  {
    "objectID": "01-basico.html#sintaxis-y-estructuras",
    "href": "01-basico.html#sintaxis-y-estructuras",
    "title": "",
    "section": "Sintaxis y estructuras",
    "text": "Sintaxis y estructuras\n\nFunciones\nLas funciones son centrales en Julia. Por ahora veremos la estructura y más adelante, definiremos algunas.\nPara ejecutar una función se utiliza la sintaxis fun(arg), esta regresará un valor, que depende de la función misma y muchas veces del tipo que tenga arg. Si fueran dos argumentos fun(arg1, arg2), etc. También se soportan argumentos con nombre fun(arg1, arg2, ...; kwarg=val) (kwargs para nombrarlos de manera sintética). En este caso, los kwargs no influyen en los tipos de salida. Esto puede parecer extraño pero es debido a las decisiones de implementación relacionadas con el desempeño.\nLas funciones se definen como sigue:\n1function fun(arg1, arg2...)\n    # ... expresiones ...\nend\n\n2function fun(arg1, arg2...; kwarg1=valor1, kwargs2...)\n    # ... expresiones ...\nend\n\n3fun(arg1, arg2...; kwarg1=valor1, kwargs2...) = expresion\n\n4(arg1, arg2...; kwarg1=valor1, kwargs2...) -&gt; expresion\n\n5fun() do x\n    x^2 # ... expresiones ...\nend\n\n1\n\nDefinición de una función simple, los tipos de los argumentos se utilizan para generar múltiples versiones de una función.\n\n2\n\nTambién se soportan argumentos nombrados, los cuales van después de ;, se debe tener en cuenta que los tipos de los argumentos nombrados no son utilizados para determinar si una función debe compilarse. Los argumentos nombrados pueden o no tener valores por omisión.\n\n3\n\nSi la función tiene una estructura simple, de una expresión, es posible ignorar function y end, usando ‘=’ para definirla.\n\n4\n\nMuchas veces es útil definir funciones anónimas, que suelen pasarse a otras funciones de orden superior.\n\n5\n\nUn embellecedor útil para generar una función anónima (definida entre do...end) que se pasa como primer argumento a fun, e.g., es equivalente a fun(x-&gt;x^2).\n\n\nEl ámbito o scope de las variables en Julia es sintáctico, que significa que se hereda del código donde las funciones fueron definidas, y no dinámico (que se hereda desde dónde se ejecuta la función). Aunque es el comportamiento de la mayoría de los lenguajes modernos, es importante conocerlo sobre todo para la creación de cerraduras sintácticas en funciones.\n\n\nExpresiones y operadores\nLas expresiones son la forma más genérica de expresar el código en Julia, comprenden operaciones aritméticas, asignación y declaración de variables, definiciones de bloques de código, llamadas de funciones, entre otras.\nCada linea suele ser una expresión, a menos que se extienda por múltiples lineas por medio de un agrupador de código o datos, estos pueden ser\n\n\nbegin\n    ...\nend\n\nlet\n    ...\nend\n\n(...)\n\n[...]\n\n[...]\n\nfor el in col\n    ...\nend\n\nwhile cond\n    ...\nend\n\nif cond\n    ...\nelseif cond\n    ...\nelse\n    ...\nend\n\nfunction fun(...)\n    ...\nend\n\ntry\n    ...\ncatch\n    ...\nfinally\n    ...\nend\n\n\nentre las más utilizadas; claramentre hay infinidad de formas de componerlas para formar los algoritmos que se esten escribiendo.\n\n\nComentarios\nLos comentarios en Julia se hacen por linea o por bloque.\nPara comentar una linea se usa el carácter hash # y define una linea comentada desde ese punto hasta el salto de linea\n\n# los siguientes son comentarios de linea completos, por lo que no se imprimirán\n#println(:hola === :hola)\n#println(typeof(:hola)) \nprintln(Symbol(\"hola mundo\"))  # este sí se imprimirá, pero este comentario no\n\nhola mundo\n\n\nPara comentar por bloque, dicho bloque se encierra entre #= ... =#\n\nprintln(\"hola mundo!\" #=Symbol(\"hola mundo\")=#)\n\nhola mundo!\n\n\n\n\nDocumentación\nLa documentación oficial se encuentra en https://docs.julialang.org; la cuál cubre el lenguaje y las bibliotecas estandar. Fuera de eso, habrá que ver los sitios y documentaciones de cada paquete, que casi siempre estan en github.\nActualmente los chatbots como ChatGPT y Gemini también pueden ser una buena fuente de información sobre el API y las formas de trabajo. Nota: siempre se debe corroborar la información, ya que suelen alucinar.\nLa manera empotrada de consultar la documentación sobre una función es con el prefijo ? en el REPL.\n\nEjemplo\nNota: Las ligas que salen estan rotas ya que no se adjunta la documentación en este manuscrito.\n\n?println(\"holi\")\n\nprintln([io::IO], xs...)\nPrint (using print) xs to io followed by a newline. If io is not supplied, prints to the default output stream stdout.\nSee also printstyled to add colors etc.\nExamples\njulia&gt; println(\"Hello, world\")\nHello, world\n\njulia&gt; io = IOBuffer();\n\njulia&gt; println(io, \"Hello\", ',', \" world.\")\n\njulia&gt; String(take!(io))\n\"Hello, world.\\n\"\n\n\n\n\n\n\nEsto también indica que debemos documentar nuestro código, en particular se hace de la siguiente forma\n```{julia}\n\n\"\"\"\n    fun(...)\n\nEsta función es un ejemplo de documentación\n\"\"\"\nfunction fun(...)\n    ...\nend\n```\n\nDefinición de variables\nLas definiciones de variables tienen la sintaxis variable = valor; las variables comunmente comienzan con una letra o _, las letras pueden ser caracteres unicode, no deben contener espacios ni puntuaciones como parte del nombre; valor es el resultado de evaluar o ejecutar una expresión.\nLos operadores más comunes son los aritméticos +, -, *, /, ÷, %, \\, ^, con precedencia y significado típico. Existen maneras compuestas de modificar una variable anteponiendo el operador aritmético al simbolo de asignación, e.g., variable += valor, que se expande a variable = variable + valor. Esto implica que variable debe estar previamente definida previo a la ejecución.\nLos operadores lógicos también tienen el significado esperado.\n\n\n\noperación\ndescripción\n\n\n\n\na && b\nAND lógico\n\n\na || b\nOR lógico\n\n\na ⊻ b\nXOR lógico\n\n\n!a\nnegación lógica\n\n\na &lt; b\ncomparación a es menor que b\n\n\na &gt; b\ncomparación a es mayor que b\n\n\na &lt;= b\ncomparación a es menor o igual que b\n\n\na &gt;= b\ncomparación a es mayor o igual que b\n\n\na == b\ncomparación de igualdad\n\n\na === b\ncomparación de igualdad (a nivel de tipo)\n\n\na != b\ncomparación de desigualdad\n\n\na !== b\ncomparación de desigualdad (a nivel de tipo)\n\n\n\nEn particular && y || implementan corto circuito de código, por lo que pueden usarse para el control de que operaciones se ejecutan. Cuando se compara a nivel de tipo 0 (entero) será diferente de 0.0 (real).\nTambién hay operadores lógicos a nivel de bit, los argumentos son enteros.\n\n\n\noperación\ndescripción\n\n\n\n\na & b\nAND a nivel de bits\n\n\na | b\nOR a nivel de bits\n\n\na ⊻ b\nXOR a nivel del bits\n\n\n~a\nnegación lógica a nivel de bits\n\n\n\n\n\nLiterales\nLos valores literales son valores explicitos que Julia permite para algunos tipos de datos, y que permiten definirlos de manera simple; permitiendonos escribir datos directamente en el código.\nLos números enteros se definen sin punto decimal, es posible usar _ como separador y dar más claridad al código. Los enteros pueden tener 8, 16, 32, o 64 bits; por omisión, se empaquetan en variables del tipo Int (Int64). Los valores hexadecimales se interpretan como enteros sin signo, y además se empaquetan al número de bits necesario minimo para contener. El comportamiento para valores en base 10 es el de hexadecimal es congruente con un lenguaje para programación de sistemas.\n\na = 100\nprintln((a, sizeof(a)))\nb = Int8(100)\nprintln((b, sizeof(b)))\nc = 30_000_000\nprintln((c, sizeof(c)))\nd = 0xffff\nprintln((d, sizeof(d)))\n\n(100, 8)\n(100, 1)\n(30000000, 8)\n(0xffff, 2)\n\n\n\n\nExisten números enteros de precisión 128 pero las operaciones al día de hoy no son implementadas de manera nativa por los procesadores; así mismo se reconocen números de punto flotante de precisión media Float16 pero la mayoría de los procesadores no tienen soporte nativo para realizar operaciones con ellos, aunque los procesadores de última generación si lo tienen.\nSi la precisión esta en duda o el contexto lo amérita, deberá especificarlo usando el constructor del tipo e.g., Int8(100), UInt8(100), Int16(100), UInt16(100), Int32(100), UInt32(100), Int64(100), UInt64(100).\nLos números de punto flotante tienen diferentes formas de definirse, teniendo diferentes efectos. Para números de precision simple, 32 bits, se definen con el sufijo f0 como 3f0. El sufijo e0 también se puede usar para definir precisión doble (64 bit). El cero del sufijo en realidad tiene el objetivo de colocar el punto decimal, en notación de ingeniería, e.g., \\(0.003\\) se define como \\(3f-3\\) o \\(3e-3\\), dependiendo del tipo de dato que se necesite. Si se omite sufijo y se pone solo punto decimal entonces se interpretará como precision doble. Los tipos son Float32 y Float64.\nLos datos booleanos se indican mediante true y false para verdadero y falso, respectivamente.\nLos caracteres son símbolos para índicar cadenas, se suelen representar como enteros pequeños en memoria. Se especifican con comillas simples 'a', 'z', '!' y soporta simbolos unicode '🤠'.\nLas cadenas de caracteres son la manera de representar textos como datos, se guardan en zonas contiguas de memoria. Se especifican con comillas dobles y también soportan símbolos unicode, e.g., \"hola mundo\", \"pato es un 🐷\".\n\n\nJulia guarda los símbolos de manera especial y pueden ser utilizados para realizar identificación de datos eficiente, sin embargo, no es buena idea saturar el sistema de manejo de símbolos por ejemplo para crear un vocabulario ya que no liberará la memoria después de definirlos ya que es un mecánismo diseñado para la representación de los programas, pero lo suficientemente robusto y bien definido para usarse en el diseño e implementación de programas de los usuarios.\nEn Julia existe la noción de símbolo, que es una cadena que además solo existe en una posición en memoria se usa el prefijo : para denotarlos.\n\nprintln(:hola === :hola)\nprintln(typeof(:hola))\nprintln(Symbol(\"hola mundo\"))\n\ntrue\nSymbol\nhola mundo\n\n\n\n\n\nControl de flujo\nEl control de flujo nos permite escoger que partes del código se ejecutaran como consecuencia de la evaluación de una expresión, esto incluye repeticiones.\nLas condicionales son el control de flujo más simple.\n\na = 10\n1if a % 2 == 0\n2    \"par\"\nelse\n3    \"impar\"\nend\n\n\n1\n\nExpresión condicional.\n\n2\n\nExpresión a ejecutarse si (1) es verdadero.\n\n3\n\nExpresión a evaluarse si (1) es falso.\n\n\n\n\n\"par\"\n\n\nSe puede ignorar la clausula else dando solo la opción de evaluar (2) si (1) es verdadero. Finalmente, note que la condicional es una expresión y devuelve un valor.\n\na = 10\nif log10(a) == 1\n    \"es 10\"\nend\n\n\"es 10\"\n\n\nTambién pueden concatenarse múltiples expresiones condicionales con elseif como se muestra a continuación.\n\na = 9\nif a % 2 == 0\n    println(\"divisible entre 2\")\nelseif a % 3 == 0\n    println(\"divisible entre 3\")\nelse\n    println(\"no divisible entre 2 y 3\")\nend\n\ndivisible entre 3\n\n\nEs común utilizar la sintaxis en Julia (short circuit) para control de flujo:\n\na = 9\n\n1println(a % 2 == 0 && \"es divisible entre dos\")\n2println(a % 3 == 0 && \"es divisible entre tres\")\n\n\n1\n\nEl resultado de la condición es falso, por lo que no se ejecutará la siguiente expresión.\n\n2\n\nEl resultado es verdadero, por lo que se ejecutará la segunda expresión.\n\n\n\n\nfalse\nes divisible entre tres\n\n\nFnalmente, existe una condicional de tres vias expresion ? expr-verdadero : expr-falso\n\na = 9\n\nprintln(a % 2 == 0 ? \"es divisible entre dos\" : \"no es divisible entre dos\")\nprintln(a % 3 == 0 ? \"es divisible entre tres\" : \"no es divisible entre tres\")\n\nno es divisible entre dos\nes divisible entre tres\n\n\n\nCiclos\nLos ciclos son expresiones de control de flujo que nos permiten iterar sobre una colección o repetir un código hasta que se cumpla alguna condición. En Julia existen dos expresiones de ciclos:\n\nfor x in colección ...expresiones... end y\nwhile condición ...expresioens... end\n\nEn el caso de for, la idea es iterar sobre una colección, esta colección puede ser un rango, i.e., inicio:fin, inicio:paso:fin, o una colección como las tuplas, los arreglos, o cualquiera que cumpla con la interfaz de colección iterable del lenguaje.\n\nfor i in 1:5\n    println(\"1er ciclo: \", i =&gt; i^2)\nend\n\nfor i in [10, 20, 30, 40, 50]\n    println(\"2do ciclo: \", i =&gt; i/10)\nend\n\n1er ciclo: 1 =&gt; 1\n1er ciclo: 2 =&gt; 4\n1er ciclo: 3 =&gt; 9\n1er ciclo: 4 =&gt; 16\n1er ciclo: 5 =&gt; 25\n2do ciclo: 10 =&gt; 1.0\n2do ciclo: 20 =&gt; 2.0\n2do ciclo: 30 =&gt; 3.0\n2do ciclo: 40 =&gt; 4.0\n2do ciclo: 50 =&gt; 5.0\n\n\nAl igual que en otros lenguajes modernos, se define la variante completa o comprehensive for que se utiliza para transformar la colección de entrada en otra colección cuya sintaxis se ejemplifica a continuación:\n\na = [i =&gt; i^2 for i in 1:5]\nprintln(a)\n\n[1 =&gt; 1, 2 =&gt; 4, 3 =&gt; 9, 4 =&gt; 16, 5 =&gt; 25]\n\n\nTambién es posible definir un generador, esto es, un código que puede generar los datos, pero que no los generará hasta que se les solicite.\n\na = (i =&gt; i^2 for i in 1:5)\nprintln(a)\nprintln(collect(a))\n\nBase.Generator{UnitRange{Int64}, var\"#3#4\"}(var\"#3#4\"(), 1:5)\n[1 =&gt; 1, 2 =&gt; 4, 3 =&gt; 9, 4 =&gt; 16, 5 =&gt; 25]\n\n\nOtra forma de hacer ciclos de intrucciones es repetir mientras se cumpla una condición:\n\ni = 0\nwhile i &lt; 5\n    i += 1\n    println(i)\nend\n\ni\n\n1\n2\n3\n4\n5\n\n\n5\n\n\n\n\n\nTuplas y arreglos en Julia\nUna tupla es un conjunto ordenado de datos que no se puede modificar y que se desea esten contiguos en memoria, la sintaxis en memoria es como sigue:\n\n1a = (2, 3, 5, 7)\nb = (10, 20.0, 30f0)\nc = 100 =&gt; 200\n2println(typeof(a))\nprintln(typeof(b))\nprintln(typeof(c))\n3a[1], a[end], b[3], c.first, c.second\n\n\n1\n\nDefine las tuplas.\n\n2\n\nImprime los tipos de las tuplas.\n\n3\n\nMuestra como se accede a los elementos de las tuplas. Julia indexa comenzando desde 1, y el término end también se utiliza para indicar el último elemento en una colección ordenada.\n\n\n\n\nNTuple{4, Int64}\nTuple{Int64, Float64, Float32}\nPair{Int64, Int64}\n\n\n(2, 7, 30.0f0, 100, 200)\n\n\nLa misma sintaxis puede generar diferentes tipos de tuplas. En el caso NTuple{4, Int4} nos indica que el tipo maneja cuatro elementos de enteros de 64 bits, los argumentos entre {} son parametros que especifican los tipos en cuestión. En el caso de Tuple se pueden tener diferentes tipos de elementos. La tupla Pair es especial ya que solo puede contener dos elementos y es básicamente para embellecer o simplificar las expresiones; incluso se crea con la sintaxis key =&gt; value y sus elementos pueden accederse mediante dos campos nombrados.\nLos arreglos son datos del mismo tipo contiguos en memoria, a diferencia de las tuplas, los elementos se pueden modificar, incluso pueden crecer o reducirse. Esto puede implicar que se alojan en zonas de memoria diferente (las tuplas se colocan en el stack y los arreglos en el heap, ver la siguiente unidad para más información). Desde un alto nivel, los arreglos en Julia suelen estar asociados con vectores, matrices y tensores, y un arsenal de funciones relacionadas se encuentran definidas en el paquete LinearAlgebra, lo cual esta más allá del alcance de este curso.\n\n1a = [2, 3, 5, 7]\nb = [10, 20.0, 30f0]\n2println(typeof(a))\nprintln(typeof(b))\n3a[1], a[end], b[3], b[2:3]\n\n\n1\n\nDefine los arreglos a y b.\n\n2\n\nMuestra los tipos de los arreglos, note como los tipos se promueven al tipo más génerico que contiene la definición de los datos.\n\n3\n\nEl acceso es muy similar a las tuplas para arreglos unidimensionales, note que es posible acceder rangos de elementos con la sintaxis ini:fin.\n\n\n\n\nVector{Int64}\nVector{Float64}\n\n\n(2, 7, 30.0, [20.0, 30.0])\n\n\n\na = [2 3;\n1     5 7]\n2display(a)\n3display(a[:, 1])\n4display(a[1, :])\n\n\n1\n\nDefinición de un arreglo bidimensional, note como se ignora la coma , en favor de la escritura por filas separadas por ;.\n\n2\n\nLa variable a es una matriz de 2x2.\n\n3\n\nEs posible acceder una columna completa usando el símbolo : para indicar todos los elementos.\n\n4\n\nDe igual forma, es posible acceder una fila completa.\n\n\n\n\n2×2 Matrix{Int64}:\n 2  3\n 5  7\n\n\n2-element Vector{Int64}:\n 2\n 5\n\n\n2-element Vector{Int64}:\n 2\n 3\n\n\n\n\nDiccionarios y conjuntos en Julia\nUn diccionario es un arreglo asociativo, i.e., guarda pares llave-valor. Permite acceder de manera eficiciente al valor por medio de la llave, así como también verificar si hay una entrada dentro del diccionario con una llave dada. La sintaxis es como sigue:\n\n1a = Dict(:a =&gt; 1, :b =&gt; 2, :c =&gt; 3)\n2a[:b] = 20\nprintln(a)\n3a[:d] = 4\nprintln(a)\n4delete!(a, :a)\na\n\n\n1\n\nDefinición del diccionario a que mapea simbolos a enteros.\n\n2\n\nCambia el valor de :b por 20.\n\n3\n\nAñade :d =&gt; 4 al diccionario a.\n\n4\n\nBorra el par con llave :a.\n\n\n\n\nDict(:a =&gt; 1, :b =&gt; 20, :c =&gt; 3)\nDict(:a =&gt; 1, :b =&gt; 20, :d =&gt; 4, :c =&gt; 3)\n\n\nDict{Symbol, Int64} with 3 entries:\n  :b =&gt; 20\n  :d =&gt; 4\n  :c =&gt; 3\n\n\nEs posible utilizar diferentes tipos siempre y cuando el tipo en cuestión defina de manera correcta la función hash sobre la llave y la verificación de igualdad ==.\nUn conjunto se representa con el tipo Set, se implementa de manera muy similar al diccionario pero solo necesita el elemento (e.g., la llave). Como conjunto implementa las operaciones clasificación de operaciones de conjuntos\n\n1a = Set([10, 20, 30, 40])\n2println(20 in a)\n3push!(a, 50)\nprintln(a)\n4delete!(a, 10)\nprintln(a)\n5println(intersect(a, [20, 35]))\n6union!(a, [100, 200])\nprintln(a)\n\n\n1\n\nDefinición del conjunto de números enteros.\n\n2\n\nVerificación de membresia al conjunto a.\n\n3\n\nAñade 50 al conjunto.\n\n4\n\nSe borra el elemento 10 del conjunto.\n\n5\n\nIntersección de a con una colección, no se modifica el conjunto a.\n\n6\n\nUnión con otra colección, se modifica a.\n\n\n\n\ntrue\nSet([50, 20, 10, 30, 40])\nSet([50, 20, 30, 40])\nSet([20])\nSet([50, 200, 20, 30, 40, 100])"
  },
  {
    "objectID": "01-basico.html#el-flujo-de-compilación-de-julia",
    "href": "01-basico.html#el-flujo-de-compilación-de-julia",
    "title": "",
    "section": "El flujo de compilación de Julia",
    "text": "El flujo de compilación de Julia\nBasta con escribir una linea de código en el REPL de Julia y esta se compilará y ejecutará en el contexto actual, usando el ámbito de variables. Esto es conveniente para comenzar a trabajar, sin embargo, es importante conocer el flujo de compilación para tenerlo en cuenta mientras se códifica, y así generar código eficiente. En particular, la creación de funciones y evitar la inestabilidad de los tipos de las variables es un paso hacia la generación de código eficiente. También es importante evitar el alojamiento de memoria dinámica siempre que sea posible. A continuación se mostrará el análisis de un código simple a diferentes niveles, mostrando que el lenguaje nos permite observar la generación de código, que últimadamente nos da cierto control y nos permite verificar que lo que se esta implementando es lo que se específica en el código. Esto no es posible en lenguajes como Python.\n\nlet\n    e = 1.1\n    println(e*e)\n    @code_typed e*e\nend\n\n1.2100000000000002\n\n\n\nCodeInfo(\n1 ─ %1 = Base.mul_float(x, y)::Float64\n└──      return %1\n) =&gt; Float64\n\n\n\nEn este código, se utiliza la estructa de agrupación de expresiones let...end. Cada expresión puede estar compuesta de otras expresiones, y casi todo es una expresión en Julia. La mayoria de las expresiones serán finalizadas por un salto de linea, pero las compuestas como let, begin, function, if, while, for, do, module estarán finalizadas con end. La indentación no importa la indentación como en Python, pero es aconsejable para mantener la legibilidad del código. La linea 2 define e inicializa la variable e; la linea 3 llama a la función println, que imprimirá el resultado de e*e en la consola. La función println esta dentro de la biblioteca estándar de Julia y siempre esta visible. La linea 4 es un tanto diferente, es una macro que toma la expresión e*e y realiza algo sobre la expresión misma, en particular @code_type muestra como se reescribe la expresión para ser ejecutada. Note como se hará una llamada a la función Base.mul_float que recibe dos argumentos y que regresará un valor Float64. Esta información es necesaria para que Julia pueda generar un código veloz, el flujo de compilación llevaría esta información a generar un código intermedio de Low Level Virtual Machine (LLVM), que es el compilador empotrado en Julia, el cual estaría generando el siguiente código LLVM (usando la macro @code_llvm):\n\n\n\n;  @ float.jl:411 within `*`\ndefine double @\"julia_*_2639\"(double %0, double %1) #0 {\ntop:\n  %2 = fmul double %0, %1\n  ret double %2\n}\n\n\n\n\nEste código ya no es específico para Julia, sino para la maquinaría LLVM. Observe la especificidad de los tipos y lo corto del código. El flujo de compilación requeriría generar el código nativo, que puede ser observado a continuación mediante la macro @code_native:\n\n\n\n   .text\n    .file   \"*\"\n    .globl  \"julia_*_2678\"                  # -- Begin function julia_*_2678\n    .p2align    4, 0x90\n    .type   \"julia_*_2678\",@function\n\"julia_*_2678\":                         # @\"julia_*_2678\"\n; ┌ @ float.jl:411 within `*`\n# %bb.0:                                # %top\n    push rbp\n    mov  rbp, rsp\n    vmulsd   xmm0, xmm0, xmm1\n    pop  rbp\n    ret\n.Lfunc_end0:\n    .size   \"julia_*_2678\", .Lfunc_end0-\"julia_*_2678\"\n; └\n                                        # -- End function\n    .section    \".note.GNU-stack\",\"\",@progbits\n\n\n\n\nEn este caso podemos observar código específico para la computadora que esta generando este documento, es posible ver el manejo de registros y el uso de instrucciones del CPU en cuestión.\nEste código puede ser eficiente dado que los tipos y las operaciones son conocidos, en el caso que esto no puede ser, la eficiencia esta perdida. Datos no nativos o la imposibilidad de determinar un tipo causarían que se generará más código nativo que terminaría necesitanto más recursos del procesador. Una situación similar ocurre cuando se aloja memoria de manera dinámica. Siempre estaremos buscando que nuestro código pueda determinar el tipo de datos para que el código generado sea simple, si es posible usar datos nativos, además de no manejar o reducir el uso de memoría dinámica."
  },
  {
    "objectID": "01-basico.html#ejemplos-de-funciones",
    "href": "01-basico.html#ejemplos-de-funciones",
    "title": "",
    "section": "Ejemplos de funciones",
    "text": "Ejemplos de funciones\nLas funciones serán una parte central de nuestros ejemplos, por lo que vale la pena retomarlas y dar ejemplos.\n\nfunction f(x)\n    x^2\nend\n\nf (generic function with 1 method)\n\n\nSiempre regresan el valor de la última expresión; note como el tipo (y no solo el valor) de retorno depende del tipo de la entrada, e.g., si x es un entero entonces x^2 será un entero, pero si x es una matriz, x^2 será una matriz.\nHay valores opcionales y kwargs, ambas tienen características diferentes:\n\nfunction f(x, t=1)\n    (x+t)^2\nend\n\nfunction g(x; t=1)\n    (x+t)^2\nend\n\ng (generic function with 1 method)"
  },
  {
    "objectID": "01-basico.html#definición-de-estructuras",
    "href": "01-basico.html#definición-de-estructuras",
    "title": "",
    "section": "Definición de estructuras",
    "text": "Definición de estructuras\n\nstruct Point\n  x::Float32\n  y::Float32\nend\n\nLa idea suele ser que todo se use de manera armoniosa\n\n\"\"\"\n  Calcula la norma de un vector representado\n  como un tupla\n\"\"\"\nfunction norm(u::Tuple)\n  s = 0f0\n\n  for i in eachindex(u)\n    s += u[i]^2\n  end\n\n  sqrt(s)\nend\n\n\"\"\"\n  Calcula la norma de un vector de 2 dimensiones\n  representado como una estructura\n\"\"\"\nfunction norm(u::Point)\n  sqrt(u.x^2 + u.y^2)\nend\n\n(norm((1, 1, 1, 1)), norm(Point(1, 1)))\n\n(2.0f0, 1.4142135f0)"
  },
  {
    "objectID": "01-basico.html#arreglos",
    "href": "01-basico.html#arreglos",
    "title": "",
    "section": "Arreglos",
    "text": "Arreglos\nUna matriz aleatoria de \\(4 \\times 6\\) se define como sigue\n\nA = rand(Float32, 4, 6)\n\n4×6 Matrix{Float32}:\n 0.00737524  0.552175  0.235799  0.162136  0.232918   0.911724\n 0.112942    0.918877  0.427888  0.84758   0.532906   0.520614\n 0.944127    0.769261  0.577461  0.625021  0.0136617  0.221724\n 0.517862    0.664317  0.143665  0.818032  0.186425   0.981887\n\n\nUn vector aleatorio de 6 dimensiones sería como sigue:\n\nx = rand(Float32, 4)\n\n4-element Vector{Float32}:\n 0.14074618\n 0.13194233\n 0.044984877\n 0.8235049\n\n\nentonces podriamos multiplicar x con A como sigue:\n\ny = x' * A\n\n1×6 adjoint(::Vector{Float32}) with eltype Float32:\n 0.484873  0.780629  0.23393  0.836422  0.257232  1.01558\n\n\n\ny'\n\n6-element Vector{Float32}:\n 0.48487285\n 0.7806288\n 0.23393025\n 0.83642167\n 0.25723183\n 1.0155756\n\n\nTambién existen otras formas para realizarla, aunque no suelen ser la mejor idea si se tienen alternativas canónicas:\n\nusing LinearAlgebra\n\ndot.(Ref(x), eachcol(A))\n\nWARNING: using LinearAlgebra.norm in module Notebook conflicts with an existing identifier.\n\n\n6-element Vector{Float32}:\n 0.48487285\n 0.7806288\n 0.23393025\n 0.8364216\n 0.25723183\n 1.0155756\n\n\nEste ejemplo muestra la técnica broadcasting que aplica una función a una colección; se indica añadiendo un punto al final del nombre de la función. Adicionalmente, hay una serie de reglas que se deben seguir para el manejo de las colecciones. La función eachcol crea un iterador sobre cada columna de la matriz A y Ref(x), nos permite que el broadcasting reconozca al vector x como un único elemento en lugar de una colección de valores.\n\nEjercicios\nDados dos vectores, cree las siguientes funciones:\n\nCalcule el coseno entre dos vectores \\(u, v\\), de dimensión \\(d\\):\n\n\\(cos(u, v) = \\frac{\\langle u, v \\rangle}{\\lVert u \\rVert \\lVert v \\rVert}\\); donde \\(\\langle u, v \\rangle = \\sum^d_i u_i \\cdot v_i\\) y \\(\\lVert \\cdot \\rVert\\) es la norma de un vector.\n\nCalcule la distancia Euclidea entre dos vectores \\(u, v\\):\n\n\\(euclidean(u, v) = \\sqrt{\\sum^d_i (u_i - v_i)^2}\\)."
  },
  {
    "objectID": "01-basico.html#paquetes-y-módulos",
    "href": "01-basico.html#paquetes-y-módulos",
    "title": "",
    "section": "Paquetes y módulos",
    "text": "Paquetes y módulos\nEl ecosistema de paquetes de Julia es una de sus mayores fortalezas, impulsado por usu gestor de paquetes Pkg, el cual viene integrado en el REPL y en la su instalación mínima; es muy robusto. Se encarga de la instalación y actualización de librerías, así como también garantiza la reproducibilidad de los proyectos. Cada ambiente de trabajo en Julia utiliza archivos como Project.toml y Manifest.toml para registrar la paquetería usada, así como las versiones necesarias de todas las dependencias.\n\nPkg en REPL\nPara entrar al modo Pkg desde cualquier sesión de Julia en el REPL se debe teclear corchete que cierra ].\nEl prompt del REPL cambiará:\n\n\n\nModo\nPrompt\n\n\n\n\nNormal (Julia)\njulia&gt;\n\n\nModo Pkg\n(@v1.10) pkg&gt;\n\n\n\nAhora se puede ver qué paquetes están instalados en tu entorno actual.\n\n\n\n\n\n\n\nComando\nAcción\n\n\n\n\nst o status\nMuestra la lista de todos los paquetes instalados y sus versiones específicas.\n\n\n\nPara añadir una paquete a tu entorno, usa el comando add.\n\n\n\nComando\nAcción\n\n\n\n\nadd Paquete\nDescarga e instala el paquete.\n\n\n\nEn el caso de que un paquete ya no sea necesario, se puede desinstalar con el comando rm (de remove).\n\n\n\nComando\nAcción\n\n\n\n\nrm Paquete\nElimina el paquete del entorno actual.\n\n\n\nFinalmente, es posible actualizar paquetes de manera individual o colectiva usando el comando up.\n\n\n\n\n\n\n\nComando\nAcción\n\n\n\n\nup o update\nActualiza todos los paquetes instalados a su última versión compatible.\n\n\nup Paquete o update Paquete\nActualiza Paquete a su última versión compatible.\n\n\n\n\nManejo de ambientes\nEl entorno o ambiente (environment) se puede especificar de manera global o por diretorio, y nos sirve para aislar las aplicaciones y no entrar en dificultades por versiones.\n\n\n\nComando\nAcción\n\n\n\n\nactivate dir\nActiva el directorio dir como ambiente.\n\n\n\nSupongamos que nos comparten un proyecto escrito en julia, lo primero que debemos hacer es activar e instanciar el ambiente; la instanciación es como sigue\n\n\n\n\n\n\n\nComando\nAcción\n\n\n\n\ninstantiate\nSe instalan todos los paquetes indicados por el ambiente.\n\n\n\nMuchas veces también cambiamos paquetes locales que requiren reactualizar el ambiente, eso se consigue con ] resolve que actualizará las nuevas dependencias que cambiaron.\n\n\nSaliendo del modo Pkg\nPara volver al modo de ejecución de código normal de Julia, se debe presionar backspace.\nEl prompt cambiará de nuevo a julia&gt; y podrás usar los paquetes que instalaste con el comando using.\nusing DataFrames, CSV\nesto traera el paquete al entorno en memoria haciendo accesibles sus métodos y estructuras públicas.\n\n\n\nUsando Pkg desde el modo normal de Julia (fuera del modo Pkg del REPL)\nExiste un paquete interno de las instalaciones de julia llamado Pkg que es el que maneja todo lo anterior, este puede ser utilizado como cualquier paquete. Basicamente tiene funciones similares a las del modo Pkg (con nombres completos).\nEjemplos:\njulia&gt; import Pkg\njulia&gt; Pkg.add(\"PlotlyLight\") \njulia&gt; Pkg.add([\"CSV\", \"DataFrames\"]) \njulia&gt; Pkg.rm(\"PlotlyLight\")\njulia&gt; Pkg.update()\njulia&gt; Pkg.status() \nAhora para el manejo de los ambientes:\njulia&gt; import Pkg\njulia&gt; Pkg.activate(\".\")\njulia&gt; Pkg.instantiate()\njulia&gt; Pkg.add(\"Statistics\")"
  },
  {
    "objectID": "01-basico.html#otras-estrategias-para-la-organización-de-código",
    "href": "01-basico.html#otras-estrategias-para-la-organización-de-código",
    "title": "",
    "section": "Otras estrategias para la organización de código",
    "text": "Otras estrategias para la organización de código\nLa función include(\"nombre_archivo.jl\") es el método más simple en Julia para organizar código en múltiples archivos. Su función es equivalente a copiar y pegar el contenido del archivo especificado directamente en la línea donde se llama a include.\nSirve para estructurar grandes scripts en archivos más pequeños y manejables; el código incluido se ejecuta en el mismo alcance (scope) donde se llamó a include. Si llamas a include en el alcance global, las funciones y variables definidas en el archivo incluido se vuelven globales. Si lo llamas dentro de un módulo, se vuelven parte de ese módulo.\nEs simple, pero no proporciona aislamiento, y puede generar conflictos de nombres si no se usa de manera adecuada.\nPor otro lado, los módulos permmiten crear espacios de nombres (namespaces) aislados y bien definidos, utiles para organizar proyectos grandes y complejos.\n\nAislamiento y alcance (Scoping)\nUn módulo actúa como una caja que encierra sus funciones y variables. Todo lo que se define dentro de un módulo es privado por defecto para evitar conflictos de nombres con código externo.\nmodule MiCalculadora\n    # Esta función es PRIVADA\n    function interna(x)\n        return x * 2\n    end\n\n    # Esta función se hace PÚBLICA con 'export'\n    export sumar\n\n    function sumar(a, b)\n        return a + b\n    end\nend\nPara que las funciones, tipos o constantes dentro de un módulo sean accesibles desde afuera, deben ser explícitamente exportadas utilizando la palabra clave export.\nLos modulos pueden anidarse.\nPara utilizar las funciones de un módulo en otro script o en el REPL, se usan dos comandos principales:\n\n\n\n\n\n\n\nComando\nAcción\n\n\n\n\nusing NombreModulo\nImporta solo los símbolos que han sido exportados por el módulo.\n\n\nimport NombreModulo\nImporta el módulo completo. Para usar sus funciones, debes prefijarlas (ej: NombreModulo.sumar(1, 2)).\n\n\n\nEn la práctica, un paquete o un proyecto grande de Julia casi siempre usa tanto include como módulos. De esta manera, include ayuda a la organización de archivos, mientras que el bloque module garantiza que todo el código esté contenido en un espacio de nombres único y limpio, evitando colisiones.\nEn particular, los paquetes pueden verse como la preparación de un módulo para su distribución, indicando los paquetes que usan (dependencias) y sus versiones especificas para los cuales fueron diseñados. También suelen incluir documentación y pruebas unitarias."
  },
  {
    "objectID": "01-basico.html#recursos-para-aprender-más-sobre-el-lenguaje",
    "href": "01-basico.html#recursos-para-aprender-más-sobre-el-lenguaje",
    "title": "",
    "section": "Recursos para aprender más sobre el lenguaje",
    "text": "Recursos para aprender más sobre el lenguaje\n\nInformación sobre como instalar Julia y flujos de trabajo simples (e.g., REPL, editores, etc.) para trabajar con este lenguaje de programación: Modern Julia Workflows https://modernjuliaworkflows.github.io/.\nLibro sobre julia Think Julia: How to Think Like a Computer Scientist https://benlauwens.github.io/ThinkJulia.jl/latest/book.html.\nCurso Introduction to computational thinking https://computationalthinking.mit.edu/Fall20/"
  },
  {
    "objectID": "refs.html",
    "href": "refs.html",
    "title": "",
    "section": "",
    "text": "Código\n\n\n\n\n\n    En esta página\n   \n  \n  References\n  \n\n\nReferences"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Prefacio",
    "section": "",
    "text": "Prefacio\n  \n  Trabajo en progreso\n  Licencia"
  },
  {
    "objectID": "index.html#trabajo-en-progreso",
    "href": "index.html#trabajo-en-progreso",
    "title": "Prefacio",
    "section": "Trabajo en progreso",
    "text": "Trabajo en progreso\nEste curso es un trabajo en progreso. Se ha presentado en version extendida como parte de la materia Recuperación de Información en Bases de Datos No Estructuradas de la maestría en Ciencia de Datos e Información de INFOTEC; en esta forma, se pretende dar una introducción más amena a las aplicaciones."
  },
  {
    "objectID": "index.html#licencia",
    "href": "index.html#licencia",
    "title": "Prefacio",
    "section": "Licencia",
    "text": "Licencia\n\nEsta obra está bajo una Licencia Creative Commons Atribución-CompartirIgual 4.0 Internacional"
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Prefacio",
    "section": "Notas",
    "text": "Notas\n\n\nPara este curso se recomienda utilizar la versión 1.10 o superior, y puede obtenerse en https://julialang.org/.↩︎"
  },
  {
    "objectID": "02-data-vis.html",
    "href": "02-data-vis.html",
    "title": "Dataframes y Visualización",
    "section": "",
    "text": "Uso de tablas de datos\n  \n  Descargando un archivo de datos CSV desde Internet\n  Filtrado\n  \n  Visualización\n  \n  Ejercicios"
  },
  {
    "objectID": "02-data-vis.html#uso-de-tablas-de-datos",
    "href": "02-data-vis.html#uso-de-tablas-de-datos",
    "title": "Dataframes y Visualización",
    "section": "Uso de tablas de datos",
    "text": "Uso de tablas de datos\nUn dataframe es una tabla de datos y visualización con Plotly; existen varios graficadores de Julia, incluso algunos nativos, pero suelen tener tiempos de compilación considerables que pueden ser poco prácticos para su uso en Colab o un curso práctico limitado en tiempo.\n\nusing CSV, DataFrames, Downloads, StatsBase, MultivariateStats\nusing PlotlyLight\nPlotlyLight.settings.use_iframe = true  # necesario para quarto / jupyter / etc.\n\ntrue\n\n\n\nDescargando un archivo de datos CSV desde Internet\nDescargaremos una tabla de internet en formato CSV y luego se cargará\n\nurl = \"https://raw.githubusercontent.com/plotly/datasets/master/iris.csv\"\n\nDownloads.download(url, \"iris.csv\")\ndf = CSV.read(\"iris.csv\", DataFrame)\n\n150×5 DataFrame125 rows omitted\n\n\n\nRow\nSepalLength\nSepalWidth\nPetalLength\nPetalWidth\nName\n\n\n\nFloat64\nFloat64\nFloat64\nFloat64\nString15\n\n\n\n\n1\n5.1\n3.5\n1.4\n0.2\nIris-setosa\n\n\n2\n4.9\n3.0\n1.4\n0.2\nIris-setosa\n\n\n3\n4.7\n3.2\n1.3\n0.2\nIris-setosa\n\n\n4\n4.6\n3.1\n1.5\n0.2\nIris-setosa\n\n\n5\n5.0\n3.6\n1.4\n0.2\nIris-setosa\n\n\n6\n5.4\n3.9\n1.7\n0.4\nIris-setosa\n\n\n7\n4.6\n3.4\n1.4\n0.3\nIris-setosa\n\n\n8\n5.0\n3.4\n1.5\n0.2\nIris-setosa\n\n\n9\n4.4\n2.9\n1.4\n0.2\nIris-setosa\n\n\n10\n4.9\n3.1\n1.5\n0.1\nIris-setosa\n\n\n11\n5.4\n3.7\n1.5\n0.2\nIris-setosa\n\n\n12\n4.8\n3.4\n1.6\n0.2\nIris-setosa\n\n\n13\n4.8\n3.0\n1.4\n0.1\nIris-setosa\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n139\n6.0\n3.0\n4.8\n1.8\nIris-virginica\n\n\n140\n6.9\n3.1\n5.4\n2.1\nIris-virginica\n\n\n141\n6.7\n3.1\n5.6\n2.4\nIris-virginica\n\n\n142\n6.9\n3.1\n5.1\n2.3\nIris-virginica\n\n\n143\n5.8\n2.7\n5.1\n1.9\nIris-virginica\n\n\n144\n6.8\n3.2\n5.9\n2.3\nIris-virginica\n\n\n145\n6.7\n3.3\n5.7\n2.5\nIris-virginica\n\n\n146\n6.7\n3.0\n5.2\n2.3\nIris-virginica\n\n\n147\n6.3\n2.5\n5.0\n1.9\nIris-virginica\n\n\n148\n6.5\n3.0\n5.2\n2.0\nIris-virginica\n\n\n149\n6.2\n3.4\n5.4\n2.3\nIris-virginica\n\n\n150\n5.9\n3.0\n5.1\n1.8\nIris-virginica\n\n\n\n\n\n\nPara observar un resumen del contenido\n\ndescribe(df)\n\n5×7 DataFrame\n\n\n\nRow\nvariable\nmean\nmin\nmedian\nmax\nnmissing\neltype\n\n\n\nSymbol\nUnion…\nAny\nUnion…\nAny\nInt64\nDataType\n\n\n\n\n1\nSepalLength\n5.84333\n4.3\n5.8\n7.9\n0\nFloat64\n\n\n2\nSepalWidth\n3.054\n2.0\n3.0\n4.4\n0\nFloat64\n\n\n3\nPetalLength\n3.75867\n1.0\n4.35\n6.9\n0\nFloat64\n\n\n4\nPetalWidth\n1.19867\n0.1\n1.3\n2.5\n0\nFloat64\n\n\n5\nName\n\nIris-setosa\n\nIris-virginica\n0\nString15\n\n\n\n\n\n\n\n\nFiltrado\nLos dataframes permiten filtrar o seleccionar datos de manera muy simple:\n\ndf_setosa = filter(r -&gt; r.Name == \"Iris-setosa\", df)\ndf_versicolor = df[df.Name .== \"Iris-versicolor\", :]\n\n50×5 DataFrame25 rows omitted\n\n\n\nRow\nSepalLength\nSepalWidth\nPetalLength\nPetalWidth\nName\n\n\n\nFloat64\nFloat64\nFloat64\nFloat64\nString15\n\n\n\n\n1\n7.0\n3.2\n4.7\n1.4\nIris-versicolor\n\n\n2\n6.4\n3.2\n4.5\n1.5\nIris-versicolor\n\n\n3\n6.9\n3.1\n4.9\n1.5\nIris-versicolor\n\n\n4\n5.5\n2.3\n4.0\n1.3\nIris-versicolor\n\n\n5\n6.5\n2.8\n4.6\n1.5\nIris-versicolor\n\n\n6\n5.7\n2.8\n4.5\n1.3\nIris-versicolor\n\n\n7\n6.3\n3.3\n4.7\n1.6\nIris-versicolor\n\n\n8\n4.9\n2.4\n3.3\n1.0\nIris-versicolor\n\n\n9\n6.6\n2.9\n4.6\n1.3\nIris-versicolor\n\n\n10\n5.2\n2.7\n3.9\n1.4\nIris-versicolor\n\n\n11\n5.0\n2.0\n3.5\n1.0\nIris-versicolor\n\n\n12\n5.9\n3.0\n4.2\n1.5\nIris-versicolor\n\n\n13\n6.0\n2.2\n4.0\n1.0\nIris-versicolor\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n39\n5.6\n3.0\n4.1\n1.3\nIris-versicolor\n\n\n40\n5.5\n2.5\n4.0\n1.3\nIris-versicolor\n\n\n41\n5.5\n2.6\n4.4\n1.2\nIris-versicolor\n\n\n42\n6.1\n3.0\n4.6\n1.4\nIris-versicolor\n\n\n43\n5.8\n2.6\n4.0\n1.2\nIris-versicolor\n\n\n44\n5.0\n2.3\n3.3\n1.0\nIris-versicolor\n\n\n45\n5.6\n2.7\n4.2\n1.3\nIris-versicolor\n\n\n46\n5.7\n3.0\n4.2\n1.2\nIris-versicolor\n\n\n47\n5.7\n2.9\n4.2\n1.3\nIris-versicolor\n\n\n48\n6.2\n2.9\n4.3\n1.3\nIris-versicolor\n\n\n49\n5.1\n2.5\n3.0\n1.1\nIris-versicolor\n\n\n50\n5.7\n2.8\n4.1\n1.3\nIris-versicolor"
  },
  {
    "objectID": "02-data-vis.html#visualización",
    "href": "02-data-vis.html#visualización",
    "title": "Dataframes y Visualización",
    "section": "Visualización",
    "text": "Visualización\nPara visualiación\n\np = plot(mode=\"markers\")\np = p.scatter(x=df_setosa.SepalLength, y=df_setosa.PetalLength, mode=\"markers\")\np = p.scatter(x=df_versicolor.SepalLength, y=df_versicolor.PetalLength, mode=\"markers\")\np.layout.title.text = \"2 tipos de flores\"\np\n\n\n\n\n\nVisualización de datos en alta dimensión\nEl plot anterior tiene un problema, solo muestra SepalLength vs PetalLength; ignorando SepalWidth y PealWidth. Es posible hacer un plot en 3 dimensiones, pero en 4 ya no es posible. Entonces, lo que se suele hacer para visualizar datos de alta dimensión es utilizar un método para reducir la dimensión. Por ejemplo PCA.\n\np = plot()\np.layout.title = \"PCA sobre Iris\"\n\nX = permutedims(Matrix{Float32}(df[:, [:SepalLength, :SepalWidth, :PetalLength, :PetalWidth]]))\n\ncolors = Dict(\n    \"Iris-setosa\" =&gt; \"blue\", \n    \"Iris-versicolor\" =&gt; \"red\", \n    \"Iris-virginica\" =&gt; \"green\"\n    )\n\npca = fit(PCA, X; maxoutdim=2)\nX2 = predict(pca, X)\ndisplay(size(X2))\np = p.scatter(\n    x=X2[1, :],\n    y=X2[2, :],\n    mode=\"markers\",\n    marker=Dict(:color =&gt; map(name-&gt;colors[name], df.Name))\n    )\np\n\n\n\n\n\n\n(2, 150)\n\n\n(a) PCA\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\nFigura 1\n\n\n\n\nAhora tenemos un mapa en 2D que contiene información de 4D; lo cual claramente podría implicar un error, ver el artículo de PCA en wikipedia, pero nos permite generar conocimiento e intuición de las relaciones entre los datos.\n\n\nEjercicios\nCalcule las matriz de distancias entre todas las muestras (4D, 150 vectores). Grafique dicha matriz como si fuera una imagen; vea la página del manual de Plotly para heatmap.\nIntentalo antes de ver una posible solución: https://colab.research.google.com/drive/1pxibakC-fYhCvFonV2n5UKB27CvZx_Vj?usp=sharing"
  },
  {
    "objectID": "03-IR.html",
    "href": "03-IR.html",
    "title": "Recuperación de Información",
    "section": "",
    "text": "Sistemas basados en recuperación de información\n  Ejemplos de implementación de search engines open source\n  Búsqueda de Texto Completo\n  \n  Problema de búsqueda\n  Velocidad de consultas\n  \n  Medidas de calidad (scores)\nLa Recuperación de Información (IR) es una disciplina multidisciplinaria que se crea a partir de la necesidad de simplificar el acceso y revisión de documentos en grandes colecciones. Estas colecciones pueden ser homogéneas o heterogéneas, tanto en su contenido como en su formato. En un inicio, se consideraban colecciones textuales pero las necesidades de información han cambiado, y ahora es común encontrar sistemas de recuperación de información sobre otros datos como imágenes o videos, o inclusive multimodales, esto es que puedan usar diferentes tipos de objetos. Un objeto puede ser un documento de texto, una imagen, o cualquier otro tipo de datos que se desee tener acceso.\nMantener un sistema de información homogéneo puede simplificar su mantenimiento enormemente, por lo que si es posible, se puede intentar mantener cierta homegeneidad. Para sistemas de fuentes abiertas como puede ser la web, esto será posible.\nEn general, se puede ver un sistema de recuperación de información en tres grandes partes:\nLa normalización puede ir desde el simple preprocesamiento de los datos hasta manipulaciones y transformaciones dependientes del dominio y el lenguaje. Una vez aplicado el modelado adecuado a las colecciones, las representaciones matemáticas suelen ser vectores de alta dimensión para cada objeto.\nEn cuanto al indexamiento se utilizarán dos tipos de algoritmos, búsqueda mediante índices invertidos y búsqueda por índices métricos. Ambas tienen sus nichos de aplicación y usarlas adecuadamente requiere conocer los problemas y sus modelados.\nLa presentación de los resultados puede ser tan simple como una lista de resultados más relevantes y una pequeña muestra del objeto, o más complejo que requiera alguna técnica de visualización. Todo esto dependerá del dominio de aplicación y la naturaleza del sistema de recuperación de información.\nEn este curso se visitarán parcialmente todas estas partes. En general se usaran conjuntos de datos previamente recolectados, aunque se invita a explorar otras colecciones."
  },
  {
    "objectID": "03-IR.html#búsqueda-de-texto-completo",
    "href": "03-IR.html#búsqueda-de-texto-completo",
    "title": "Recuperación de Información",
    "section": "Búsqueda de Texto Completo",
    "text": "Búsqueda de Texto Completo\nTal vez la tarea más emblemática de la Recuperación de Información es la búsqueda de texto completo. El problema consiste en dado un corpus grande de documentos, preprocesarlo para crear una estructura de búsqueda que permita resolver consultas de manera eficiente. Una consulta es un texto corto que específica lo que se desea encontrar en la colección. En particular, es un ejemplo de lo que se desea. Esto lleva a que la estructura de búsqueda resuelve búsquedas por similitud.\nLa similitud, es entonces un tema central, pero para medirla lo primero es tener una representación de los datos que capture las propiedades deseadas (que serán después evaluadas para medir la similitud). La manera más tradicional de hacerlo, es el uso de un modelo basado en bolsa de palabras (BOW). En dicho modelo, el texto es preprocesado, toquenizado y vectorizado.\n\nEl preprocesamiento incluye tratamientos tan simples como eliminar símbolos no deseados, eliminación de variantes léxicas, reducción a raíces o lemas, corrección de ortografía, eliminiación de palabras comunes (stop words).\nEl toquenizado es el proceso donde el texto es partido, en frases u oraciones, y finalmente en palabras y símbolos que son unidades completas. En este punto también es posible realizar normalizaciones, así como también realizar limpieza basada en estadísticas de los términos.\nEl vectorizado utiliza el vocabulario de una colección \\(\\{t_i\\}\\) para generar una matriz de la colección, i.e., un vector por documento.\n\nAl proceso de modelar una colección mediante un vocabulario y luego ser capaces de generar una representación manejable por una computadora se le llama modelo de lenguaje.\n\nProblema de búsqueda\nUna vez que se tiene el modelo de lenguaje y que fue usado para vectorizar una colección \\(X\\), la idea es ser capaces de resolver consultas \\(q \\in Q\\), i.e., encontrar un subconjunto de \\(X\\) de tamaño \\(k\\) que más se parezca a \\(q\\). Las consultas deben ser codificadas al mismo espacio que los documentos, i.e., espacio vectorial. Entonces el problema se transforma en encontrar los elementos más parecidos, que dada la representación, es conveniente usar el coseno entre vectores:\n\\[ \\cos(u, q) = \\frac{\\langle u_i, q_i \\rangle}{\\sqrt{\\sum_i u_i^2} \\cdot \\sqrt{\\sum_i q_i^2}} \\]\nAsí mismo, \\(d(u, q) = \\arccos(\\cos(u, q))\\) sería el ángulo entre ambos vectores, que además es una métrica. El problema entonces se transforma en encontrar los vecinos más cercanos en la colección, esto es, si deseamos \\(k\\) resultados de una consulta, estaríamos deseando encontrar aquel subconjunto \\(knn\\) de la colección tal que \\(\\sum_{v \\in knn} d(v, q)\\) sea mínimo comparado con todo subconjunto de tamaño \\(k\\) de la colección de documentos.\nEs común normalizar previamente para tener vectores de norma 1 de tal forma que el denominador es innecesario. También suele ser innecesario calcular el \\(\\arccos\\) a menos que se requiera una métrica; si solo se requiere una distancia, y no una similitud como sería el coseno, se puede hacer \\(1 - cos(u, v)\\) en su lugar.\n\n\nVelocidad de consultas\nPara mejorar la solución de consultas, es posible crear una estructura de datos que simplifique el proceso de encontrar el subconjunto \\(knn\\). En este problema, con una representación basada en bolsa de palabras, la estructura más adecuada es el índice invertido."
  },
  {
    "objectID": "03-IR.html#medidas-de-calidad-scores",
    "href": "03-IR.html#medidas-de-calidad-scores",
    "title": "Recuperación de Información",
    "section": "Medidas de calidad (scores)",
    "text": "Medidas de calidad (scores)\nLa medición de la calidad en un sistema de búsqueda es fundamental para obtener un sistema de RI adecuado. La idea básica es que un algoritmo recupere la información adecuada para solventar los requerimientos de las consultas hechas por usuarios. Dicho de otra forma, si se piden \\(k\\) documentos relacionados a una consulta \\(q\\), se medirá que porcentaje de esos \\(k\\) son relevantes para el usuario. La evaluación de relevancia de un documento es hecha previamente por usuarios expertos en el dominio del corpus y las consultas. A esta función de relevancia se le llama \\(\\textsf{recall}\\).\n\\[ \\textsf{recall}(\\text{doc. recuperados}, \\text{doc. esperados}) = \\frac{\\left| \\text{doc. recuperados} \\cap \\text{doc esperados} \\right|}{\\left|\\text{doc. esperados}\\right|} \\]\nNote que no se espera que cada conjunto de resultados sea de tamaño idéntico, aunque esta será la norma en nuestro curso. Para obtener una estadística fiable, la relevancia será promediada para obtener la calidad del modelo o algoritmo ante un conjunto de consultas. Llamaremos \\(\\textsf{macrorecall}\\) al promedio de los recalls varias consultas.\n\\[ \\textsf{macrorecall}(R, G) = \\frac{1}{|G|} \\sum_i \\textsf{recall}(R_i, G_i)\\]\nEl conjunto \\(R\\) es el conjunto de resultados recuperados para un conjunto de consultas, mientras que \\(G\\) es un conjunto especial de resultados que suele llamarse gold standard, que sería esa el conjunto de resultados fiables obtenidos a través de la evaluación de expertos humanos.\nEs costoso y tardado construir un gold standard para una tarea de recuperación de información, y más aún, para conjuntos de datos grandes. En este curso ignoramos esta parte crucial de todo esquema de recuperación de información y lo haremos de manera perceptiva."
  },
  {
    "objectID": "06-about.html",
    "href": "06-about.html",
    "title": "Conclusiones",
    "section": "",
    "text": "Acerca de este curso\nConcluyendo nuestro curso sobre la Recuperación de Información Multimodal, hemos visto cómo los paquetes TextSearch.jl y SimilaritySearch.jl se establecen como herramientas de Recuperación de Información escalables. Hemos aprendido a crear índices eficientes que permiten búsquedas rápidas, ya sea consultando grandes colecciones de texto mediante el uso de embeddings avanzados, o navegando vastas galerías de imágenes a través de modelos de visión. Lo más destacable es la capacidad de integrar estos dominios en un entorno multimodal, permitiendo a los usuarios buscar con una imagen para encontrar textos relevantes o viceversa. Al implementar el paquete, aprendimos a calibrar parámetros que intercambian velocidad y calidad de los resultados (recall), utilizando técnicas de auto-optimización que ajustan la estructura del grafo para garantizar que nuestras búsquedas no solo sean rápidas, sino que también devuelvan los vecinos más precisos en cada consulta."
  },
  {
    "objectID": "06-about.html#acerca-de-este-curso",
    "href": "06-about.html#acerca-de-este-curso",
    "title": "Conclusiones",
    "section": "Acerca de este curso",
    "text": "Acerca de este curso\n\nEric Sadit Téllez Avila eric.tellez@infotec.mx\nhttps://github.com/sadit/SimilaritySearch.jl\nhttps://github.com/sadit/SimilaritySearchDemos\nhttps://github.com/sadit/TextSearch.jl\nhttps://ingeotec.github.io/"
  }
]